{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool.all as gt\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvGraphsPath=\"../graphs/csv/\"\n",
    "csvGraphFileName=\"facebook_combined.csv\"\n",
    "csvGraphFilePath=csvGraphsPath+csvGraphFileName\n",
    "fbGraph=gt.load_graph_from_csv(csvGraphFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F=ig.Graph.Read(\"../graphs/ncol/facebook_combined.txt\",format=\"ncol\").as_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbWorkers=31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import math\n",
    "def colorDistribution(nbColors):\n",
    "    assert nbColors>=1\n",
    "    base=13\n",
    "    maxValues=4\n",
    "    nbValues=math.ceil(nbColors/base)\n",
    "    if nbValues==1:\n",
    "        values=[1]\n",
    "    else:\n",
    "        denominatorV=min(maxValues,nbValues)\n",
    "        values=[min(1,0.5+0.5*v/(denominatorV-1)) for v in range(denominatorV)]\n",
    "\n",
    "    if nbColors==1:\n",
    "        hues=[0]\n",
    "    else:\n",
    "        denominatorH=min(base,nbColors)\n",
    "        hues=[h/(denominatorH) for h in range(denominatorH)]\n",
    "    sats=[1]\n",
    "    nbSat=1\n",
    "    if nbValues>maxValues:\n",
    "        nbSat=math.ceil(nbColors/(denominatorH*denominatorV))\n",
    "        sats=[min(1,0.4+0.5*s/(nbSat-1)) for s in range(nbSat)]\n",
    "    HSVs=[]\n",
    "    \n",
    "    for value in values[::-1]:\n",
    "        for i in range(len(hues)):\n",
    "            for sat in sats[::-1]:\n",
    "                if i%2==0:\n",
    "                    HSVs.append((hues[i//2],sat,value))\n",
    "                else:\n",
    "                    HSVs.append((hues[-i//2],sat,value))\n",
    "\n",
    "    colours = [colorsys.hsv_to_rgb(hue, sat, value) for hue,sat,value in HSVs]\n",
    "    return colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCommunities(graph):\n",
    "    detect_communities=[graph.community_multilevel,\n",
    "                        graph.community_label_propagation,\n",
    "                        graph.community_leading_eigenvector]\n",
    "    \n",
    "    partition=detect_communities[0]()\n",
    "    \n",
    "    colours=colorDistribution(len(partition))\n",
    "\n",
    "    for idx, c in enumerate(partition):\n",
    "        color=colours[idx]\n",
    "        for v in c:\n",
    "            partition.graph.vs[v][\"color\"]=color\n",
    "            partition.graph.vs[v][\"cluster\"]=idx\n",
    "            for e in partition.graph.incident(v):\n",
    "                ed=partition.graph.es[e]\n",
    "                if ed.source in c and ed.target in c:\n",
    "                    ed[\"color\"]=[0.,0.,0.,1.]\n",
    "                else:\n",
    "                    ed[\"color\"]=[0.5,0.5,0.5,1.]\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseVertex(graph):\n",
    "    assert len(graph.vs)>0, \"Can't choose a vertex in an empty graph.\" \n",
    "    node=None\n",
    "    minBetweenness = -1\n",
    "    for idx, betweenness in enumerate(graph.betweenness()):\n",
    "        if betweenness < minBetweenness or minBetweenness == -1 :\n",
    "            node= idx\n",
    "        if betweenness==0:\n",
    "            break\n",
    "    assert node is not None\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanceCrit(value):\n",
    "    outputs=[0,0,5,10]\n",
    "    if value>=len(outputs):\n",
    "        return outputs[-1]\n",
    "    return outputs[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxMinPCCNodeSelection(dictPCC):\n",
    "    assert dictPCC!={}\n",
    "    chosenId=None\n",
    "    nbNodes=len(list(dictPCC.values())[0])\n",
    "    maxDist=-1\n",
    "    maxSumDist=-1\n",
    "    maxDistNode=None\n",
    "    for nodeId in range(nbNodes):\n",
    "        if nodeId not in dictPCC.keys():\n",
    "            minDist=-1\n",
    "            minDistNode=nodeId\n",
    "            for chosenNode in dictPCC.keys():\n",
    "                if minDist==-1 or dictPCC[chosenNode][nodeId]<minDist:\n",
    "                    minDist=dictPCC[chosenNode][nodeId]\n",
    "            #if equivalent on criterion 1, calculate criterion 2\n",
    "            sumDist=-1\n",
    "            if maxSumDist==-1 or minDist==maxDist:\n",
    "                #sumDist=sum([dictPCC[chosenNode][nodeId] for chosenNode in dictPCC.keys()])\n",
    "                #sumDist=random()\n",
    "                sumDist=sum([distanceCrit(dictPCC[chosenNode][nodeId]) for chosenNode in dictPCC.keys()])\n",
    "            #if better crit1 or equal crit1 but better crit2\n",
    "            if minDist>maxDist or (minDist==maxDist and sumDist>maxSumDist):\n",
    "                maxDist=minDist\n",
    "                maxDistNode=minDistNode\n",
    "                maxSumDist=sumDist\n",
    "    chosenId=maxDistNode\n",
    "    return chosenId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxShortestPathNodesSelection(graph,nbNodes,boundaryNodes=[]):\n",
    "    assert len(graph.vs)-len(boundaryNodes)>= nbNodes, \"{} {} {}\".format(len(graph.vs),nbNodes,len(boundaryNodes))\n",
    "    if boundaryNodes==[]:\n",
    "        chosenIds=[chooseVertex(graph)]\n",
    "    else:\n",
    "        chosenIds=boundaryNodes.copy()\n",
    "    #BFS initial des noeuds dans chosenIds\n",
    "    matPCC=graph.shortest_paths_dijkstra(chosenIds)\n",
    "    dictPCC={chosenId:matPCC[idxPCC] for idxPCC,chosenId in enumerate(chosenIds)}\n",
    "    \n",
    "    #nbNodes fois\n",
    "    while len(chosenIds)-len(boundaryNodes)<nbNodes:\n",
    "        chosenNodeId=maxMinPCCNodeSelection(dictPCC)\n",
    "\n",
    "        #BFS du nouveau noeud\n",
    "        dictPCC[chosenNodeId]=graph.shortest_paths_dijkstra(chosenNodeId)[0] #On prend la ligne de la matrice qui correspond au noeud\n",
    "        chosenIds.append(chosenNodeId)\n",
    "    assert len(chosenIds)==len(boundaryNodes)+nbNodes\n",
    "    return chosenIds[len(boundaryNodes):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineBoundary(graph, clusterVertices, clusterId):\n",
    "    boundaryVertices=set()\n",
    "    for v in clusterVertices: #Trouver les successeurs hors cluster aka les noeuds frontaliers au cluster\n",
    "        boundaryVertices.update([bv for bv in v.successors() if bv[\"cluster\"]!=clusterId])\n",
    "    boundaryVertices=list(boundaryVertices)\n",
    "    \n",
    "    return boundaryVertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBoundedCluster(boundedCluster,workerIds,clusterId):\n",
    "    for node in boundedCluster.vs:\n",
    "        if node[\"name\"]in boundedCluster.vs[workerIds][\"name\"]:\n",
    "            node[\"shape\"]=\"triangle\"\n",
    "\n",
    "    ig.plot(boundedCluster,\"../graphs/img/cluster{}.png\".format(clusterId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignWorkersInCommunity(graph,clusterGraph,clusterId):\n",
    "    clusterVertices=[v for v in graph.vs if v[\"cluster\"]==clusterId]\n",
    "    \n",
    "    boundaryVertices=[]\n",
    "    boundaryVertices=defineBoundary(graph,clusterVertices,clusterId)\n",
    "    \n",
    "    boundedCluster=graph.induced_subgraph(boundaryVertices+clusterVertices)\n",
    "    \n",
    "    #Réidentification des noeuds du graphe global vers le sous-graphe\n",
    "    #clusterVertices=[boundedCluster.vs.find(v[\"name\"]) for v in clusterVertices]\n",
    "    boundaryVertices=[boundedCluster.vs.find(v[\"name\"]) for v in boundaryVertices]\n",
    "    boundaryVerticesIds=[bv.index for bv in boundaryVertices]\n",
    "    \n",
    "    workerIds=maxShortestPathNodesSelection(boundedCluster,clusterGraph.vs[clusterId][\"nb_workers\"],boundaryVerticesIds)\n",
    "    \n",
    "    #drawBoundedCluster(boundedCluster,workerIds,clusterId)\n",
    "    \n",
    "    return boundedCluster.vs[workerIds][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxNodesWithDistConstraint(matPCC, candidatesIds, minDist):\n",
    "    maxCandidates=set()\n",
    "    \n",
    "    sets={idx:set([pos for pos, val in enumerate(matPCC[idx]) if val==0 or val>=minDist]) for idx in candidatesIds}\n",
    "    setsLengths={k:len(v) for k,v in sets.items()}\n",
    "    sortedLengthsIds=sorted(list(setsLengths.keys()), key=lambda k: setsLengths[k], reverse=True)\n",
    "    #print(sortedLengthsIds)\n",
    "    #print(setsLengths)\n",
    "    \n",
    "    for idx in sortedLengthsIds:\n",
    "        currentCandidates=sets[idx]\n",
    "        toRemove=set()\n",
    "        for candidate in currentCandidates:\n",
    "            subCandidates=sets[candidate]\n",
    "            toRemove=toRemove.union(currentCandidates.difference(subCandidates))\n",
    "        #print(toRemove)\n",
    "        finalists=currentCandidates.difference(toRemove)\n",
    "        if len(finalists)>len(maxCandidates):\n",
    "            maxCandidates=finalists\n",
    "    return maxCandidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgraphCapacity(graph, minDist):\n",
    "    nodes=graph.vs\n",
    "    candidates=set()\n",
    "    matPCC=graph.shortest_paths_dijkstra()\n",
    "\n",
    "    for i in range(len(matPCC)):\n",
    "        for j in range(len(matPCC)):\n",
    "            if i!=j and matPCC[i][j]>=minDist:\n",
    "                candidates.add(nodes[i])\n",
    "\n",
    "    compatiblePositions=[idx for idx,n in enumerate(nodes) if n in candidates]\n",
    "    candidates=maxNodesWithDistConstraint(matPCC, compatiblePositions, minDist)\n",
    "    \n",
    "    print(\"len(c)\",len(candidates),\"len(n)\",len(nodes))\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capacityBasedWorkerAssignment(graph,partition,clusterGraph,remainingWorkers):\n",
    "    assignedWorkers=remainingWorkers#0\n",
    "    \n",
    "    for clusterId, subgraph in enumerate(partition.subgraphs()):\n",
    "        diameter=subgraph.diameter()\n",
    "        radius=int(subgraph.radius())\n",
    "        print(\"d\",diameter,\"r\", radius)\n",
    "        for eccentricity in range(2,diameter+1):\n",
    "            print(\"e\",eccentricity)\n",
    "            subgraphCapacity(subgraph,eccentricity)\n",
    "    assert assignedWorkers==remainingWorkers, \"Only {} assigned workers out of {}\".format(assignedWorkers,remainingWorkers)\n",
    "    return clusterGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeOrderedRoundRobinWorkerAssignement(graph,partition,clusterGraph,remainingWorkers):\n",
    "    graphSize=len(graph.vs)\n",
    "    relativeSizes=[len(partition.subgraph(int(cluster[\"name\"][1:])).vs)/graphSize for cluster in clusterGraph.vs]\n",
    "\n",
    "    sortedIdxPerSize=sorted(range(len(relativeSizes)), key=lambda k: relativeSizes[k], reverse=True)\n",
    "    sortedSizes=sorted(relativeSizes)\n",
    "\n",
    "    #Round Robin par ordre de taille des clusters\n",
    "    currentCluster=0\n",
    "    while remainingWorkers>0:\n",
    "        currentSortedCluster=sortedIdxPerSize[currentCluster]\n",
    "        if clusterGraph.vs[currentSortedCluster][\"nb_workers\"]<len(partition.subgraph(currentSortedCluster).vs):\n",
    "            clusterGraph.vs[currentSortedCluster][\"nb_workers\"]+=1\n",
    "            remainingWorkers-=1\n",
    "        currentCluster+=1\n",
    "        if currentCluster>=len(clusterGraph.vs):\n",
    "            currentCluster=0\n",
    "    return clusterGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeProRataWorkerAssignement(graph,partition,clusterGraph,remainingWorkers):\n",
    "    graphSize=len(graph.vs)\n",
    "    relativeSizes=[len(partition.subgraph(int(cluster[\"name\"][1:])).vs)/graphSize for cluster in clusterGraph.vs]\n",
    "\n",
    "    proRataWorkers=[remainingWorkers*size for size in relativeSizes]\n",
    "    intProRataWorkers=[int(prw) for prw in proRataWorkers]\n",
    "    \n",
    "    assignedWorkers=sum(intProRataWorkers)\n",
    "    if assignedWorkers < remainingWorkers:\n",
    "        remainingProRataWorkers=[prw - prw//1 for prw in proRataWorkers]\n",
    "        sortedIdx=sorted(range(len(remainingProRataWorkers)), key=lambda k: remainingProRataWorkers[k], reverse=True)\n",
    "\n",
    "        for i in range(remainingWorkers-assignedWorkers):\n",
    "            intProRataWorkers[sortedIdx[i]]+=1\n",
    "            assignedWorkers+=1\n",
    "        \n",
    "    for idx, cluster in enumerate(clusterGraph.vs):\n",
    "        cluster[\"nb_workers\"]+=intProRataWorkers[idx]\n",
    "    \n",
    "    assert assignedWorkers==remainingWorkers, \"Only {} assigned workers out of {}\".format(assignedWorkers,remainingWorkers)\n",
    "    return clusterGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diameterProRataWorkerAssignement(graph,partition,clusterGraph,remainingWorkers):\n",
    "\n",
    "    diameters=[subgraph.diameter() for subgraph in partition.subgraphs()]\n",
    "    sumDiameters=sum(diameters)\n",
    "    \n",
    "    proRataWorkers=[remainingWorkers*diameter/sumDiameters for diameter in diameters]\n",
    "    intProRataWorkers=[int(prw) for prw in proRataWorkers]\n",
    "    \n",
    "    assignedWorkers=sum(intProRataWorkers)\n",
    "    if assignedWorkers < remainingWorkers:\n",
    "        remainingProRataWorkers=[prw - prw//1 for prw in proRataWorkers]\n",
    "        sortedIdx=sorted(range(len(remainingProRataWorkers)), key=lambda k: remainingProRataWorkers[k], reverse=True)\n",
    "\n",
    "        for i in range(remainingWorkers-assignedWorkers):\n",
    "            intProRataWorkers[sortedIdx[i]]+=1\n",
    "            assignedWorkers+=1\n",
    "        \n",
    "    for idx, cluster in enumerate(clusterGraph.vs):\n",
    "        cluster[\"nb_workers\"]+=intProRataWorkers[idx]\n",
    "    \n",
    "    assert assignedWorkers==remainingWorkers, \"Only {} assigned workers out of {}\".format(assignedWorkers,remainingWorkers)\n",
    "    return clusterGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diameterWorkerAssignment(graph,partition,clusterGraph,remainingWorkers):\n",
    "    diameters=[subgraph.diameter() for subgraph in partition.subgraphs()]\n",
    "    \n",
    "    workers=[diameter//2+diameter%2 for diameter in diameters]\n",
    "    assignedWorkers=sum(workers)\n",
    "    for idx, cluster in enumerate(clusterGraph.vs):\n",
    "        cluster[\"nb_workers\"]+=workers[idx]\n",
    "    \n",
    "    while assignedWorkers>remainingWorkers:\n",
    "        sortedIdx=sorted(range(len(workers)), key=lambda k: workers[k], reverse=True)\n",
    "\n",
    "        for i in range(assignedWorkers-remainingWorkers):\n",
    "            if clusterGraph.vs[sortedIdx[i%len(sortedIdx)]][\"nb_workers\"]>1:\n",
    "                clusterGraph.vs[sortedIdx[i%len(sortedIdx)]][\"nb_workers\"]-=1\n",
    "                assignedWorkers-=1\n",
    "    \n",
    "    if assignedWorkers<remainingWorkers:\n",
    "        clusterGraph=sizeOrderedRoundRobinWorkerAssignement(graph,partition,clusterGraph,remainingWorkers-assignedWorkers)\n",
    "        assignedWorkers=remainingWorkers\n",
    "    \n",
    "    assert assignedWorkers==remainingWorkers, \"Only {} assigned workers out of {}\".format(assignedWorkers,remainingWorkers)\n",
    "    return clusterGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignWorkers(graph,nWorkers):\n",
    "    assert nWorkers>=0, \"{} workers to assign: Number of workers to assign must be positive or zero\".format(nWorkers)\n",
    "    assert len(graph.vs)>=nWorkers, \"{} workers to assign on {} nodes: Can't assign more workers than there are vertices\".format(nWorkers,len(graph.vs))\n",
    "    partition=findCommunities(graph)\n",
    "    \n",
    "    clusterGraph=partition.cluster_graph(\"first\")\n",
    "\n",
    "    for idx, cluster in enumerate(clusterGraph.vs):\n",
    "        cluster[\"name\"]=\"C{}\".format(idx)\n",
    "\n",
    "    workerIds=[]\n",
    "    clusterIds=[]\n",
    "    if len(partition)<nWorkers:\n",
    "        #Chaque cluster aura au moins un worker en lui\n",
    "        for cluster in clusterGraph.vs:\n",
    "            cluster[\"nb_workers\"]=1\n",
    "        \n",
    "        #Attribuer le nombre de workers réel\n",
    "        remainingWorkers=nWorkers-len(clusterGraph.vs)\n",
    "        \n",
    "        workerAssignment=[sizeProRataWorkerAssignement,\n",
    "                          sizeOrderedRoundRobinWorkerAssignement,\n",
    "                          diameterProRataWorkerAssignement,\n",
    "                          diameterWorkerAssignment,\n",
    "                          capacityBasedWorkerAssignment,\n",
    "                          #subpartitioning\n",
    "                         ]\n",
    "        %time clusterGraph=workerAssignment[4](graph, partition,clusterGraph, remainingWorkers)\n",
    "\n",
    "        clusterIds=range(len(partition))\n",
    "        \n",
    "    elif len(partition)==nWorkers:\n",
    "        #1cluster/1worker\n",
    "        for cluster in clusterGraph.vs:\n",
    "            cluster[\"nb_workers\"]=1\n",
    "        clusterIds=range(len(partition))\n",
    "    else:\n",
    "        clusterIds=maxShortestPathNodesSelection(clusterGraph,nWorkers)\n",
    "        for cluster in clusterGraph.vs:\n",
    "            if cluster.index in clusterIds:\n",
    "                cluster[\"nb_workers\"]=1\n",
    "            else:\n",
    "                cluster[\"nb_workers\"]=0\n",
    "\n",
    "    #Etape2\n",
    "    #for chaque cluster de workers\n",
    "    #prendre son sous-graphe+ les noeuds frontaliers d'autres clusters, BFS des frontières et Etape1 nb_workers fois\n",
    "    for clusterId in clusterIds:\n",
    "        %time workerIds.extend(assignWorkersInCommunity(graph,clusterGraph,clusterId))\n",
    "    \n",
    "    assert len(workerIds)==nWorkers, \"Assigned {} workers instead of {}\".format(len(workerIds),nWorkers)\n",
    "    return workerIds,partition,clusterGraph,clusterIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d 3 r 2\n",
      "e 2\n",
      "len(c) 25 len(n) 350\n",
      "e 3\n",
      "len(c) 2 len(n) 350\n",
      "d 5 r 3\n",
      "e 2\n",
      "len(c) 23 len(n) 431\n",
      "e 3\n",
      "len(c) 5 len(n) 431\n",
      "e 4\n",
      "len(c) 3 len(n) 431\n",
      "e 5\n",
      "len(c) 2 len(n) 431\n",
      "d 2 r 1\n",
      "e 2\n",
      "len(c) 23 len(n) 435\n",
      "d 2 r 1\n",
      "e 2\n",
      "len(c) 11 len(n) 423\n",
      "d 4 r 2\n",
      "e 2\n",
      "len(c) 12 len(n) 543\n",
      "e 3\n",
      "len(c) 2 len(n) 543\n",
      "e 4\n",
      "len(c) 2 len(n) 543\n",
      "d 5 r 3\n",
      "e 2\n",
      "len(c) 7 len(n) 323\n",
      "e 3\n",
      "len(c) 6 len(n) 323\n",
      "e 4\n",
      "len(c) 5 len(n) 323\n",
      "e 5\n",
      "len(c) 2 len(n) 323\n",
      "d 8 r 4\n",
      "e 2\n",
      "len(c) 4 len(n) 121\n",
      "e 3\n",
      "len(c) 3 len(n) 121\n",
      "e 4\n",
      "len(c) 3 len(n) 121\n",
      "e 5\n",
      "len(c) 3 len(n) 121\n",
      "e 6\n",
      "len(c) 3 len(n) 121\n",
      "e 7\n",
      "len(c) 2 len(n) 121\n",
      "e 8\n",
      "len(c) 2 len(n) 121\n",
      "d 3 r 2\n",
      "e 2\n",
      "len(c) 20 len(n) 548\n",
      "e 3\n",
      "len(c) 1 len(n) 548\n",
      "d 3 r 2\n",
      "e 2\n",
      "len(c) 2 len(n) 73\n",
      "e 3\n",
      "len(c) 2 len(n) 73\n",
      "d 3 r 2\n",
      "e 2\n",
      "len(c) 7 len(n) 237\n",
      "e 3\n",
      "len(c) 3 len(n) 237\n",
      "d 2 r 1\n",
      "e 2\n",
      "len(c) 3 len(n) 25\n",
      "d 2 r 1\n",
      "e 2\n",
      "len(c) 13 len(n) 60\n",
      "d 3 r 2\n",
      "e 2\n",
      "len(c) 13 len(n) 206\n",
      "e 3\n",
      "len(c) 1 len(n) 206\n",
      "d 5 r 3\n",
      "e 2\n",
      "len(c) 4 len(n) 226\n",
      "e 3\n",
      "len(c) 6 len(n) 226\n",
      "e 4\n",
      "len(c) 4 len(n) 226\n",
      "e 5\n",
      "len(c) 2 len(n) 226\n",
      "d 2 r 1\n",
      "e 2\n",
      "len(c) 4 len(n) 19\n",
      "d 2 r 2\n",
      "e 2\n",
      "len(c) 4 len(n) 19\n",
      "CPU times: user 5.37 s, sys: 156 ms, total: 5.53 s\n",
      "Wall time: 5.47 s\n",
      "CPU times: user 6.93 ms, sys: 359 µs, total: 7.29 ms\n",
      "Wall time: 6.91 ms\n",
      "CPU times: user 111 ms, sys: 3 µs, total: 111 ms\n",
      "Wall time: 111 ms\n",
      "CPU times: user 245 ms, sys: 7.83 ms, total: 253 ms\n",
      "Wall time: 252 ms\n",
      "CPU times: user 200 ms, sys: 0 ns, total: 200 ms\n",
      "Wall time: 200 ms\n",
      "CPU times: user 163 ms, sys: 129 µs, total: 163 ms\n",
      "Wall time: 162 ms\n",
      "CPU times: user 66.1 ms, sys: 0 ns, total: 66.1 ms\n",
      "Wall time: 65.8 ms\n",
      "CPU times: user 11.9 ms, sys: 0 ns, total: 11.9 ms\n",
      "Wall time: 11.7 ms\n",
      "CPU times: user 17.5 ms, sys: 0 ns, total: 17.5 ms\n",
      "Wall time: 17.2 ms\n",
      "CPU times: user 4.15 ms, sys: 104 µs, total: 4.25 ms\n",
      "Wall time: 4.26 ms\n",
      "CPU times: user 53.1 ms, sys: 8.63 ms, total: 61.8 ms\n",
      "Wall time: 61.5 ms\n",
      "CPU times: user 1.1 ms, sys: 53 µs, total: 1.15 ms\n",
      "Wall time: 1.16 ms\n",
      "CPU times: user 1.15 ms, sys: 56 µs, total: 1.21 ms\n",
      "Wall time: 1.21 ms\n",
      "CPU times: user 2.9 ms, sys: 0 ns, total: 2.9 ms\n",
      "Wall time: 2.91 ms\n",
      "CPU times: user 12.2 ms, sys: 0 ns, total: 12.2 ms\n",
      "Wall time: 12.2 ms\n",
      "CPU times: user 906 µs, sys: 0 ns, total: 906 µs\n",
      "Wall time: 911 µs\n",
      "CPU times: user 1.1 ms, sys: 32 µs, total: 1.13 ms\n",
      "Wall time: 1.14 ms\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Assigned 16 workers instead of 31",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-cc634eef4825>\u001b[0m in \u001b[0;36massignWorkers\u001b[0;34m(graph, nWorkers)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'workerIds.extend(assignWorkersInCommunity(graph,clusterGraph,clusterId))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkerIds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnWorkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Assigned {} workers instead of {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkerIds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnWorkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mworkerIds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclusterGraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclusterIds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Assigned 16 workers instead of 31"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'workerIds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-dbbfeb45e7dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'workerIds,partition,clusterGraph,clusterIds=assignWorkers(F,nbWorkers)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkerIds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'workerIds' is not defined"
     ]
    }
   ],
   "source": [
    "%time workerIds,partition,clusterGraph,clusterIds=assignWorkers(F,nbWorkers)\n",
    "print(workerIds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we distantiated workers based on the whole graph (as if one unique community)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%time workerIds=F.vs[maxShortestPathNodesSelection(F,nbWorkers)][\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, cluster in enumerate(clusterGraph.vs):\n",
    "    if cluster.index in clusterIds:\n",
    "        cluster[\"size\"]=50\n",
    "    cluster[\"color\"]=partition.subgraph(idx).vs[0][\"color\"]\n",
    "    cluster[\"label\"]=\"{}({})\".format(idx,cluster[\"nb_workers\"])\n",
    "ig.plot(clusterGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in F.vs:\n",
    "    if v[\"name\"] in workerIds:\n",
    "        v[\"size\"]=25\n",
    "        v[\"shape\"]=\"triangle\"\n",
    "    else:\n",
    "        v[\"size\"]=1\n",
    "        v[\"shape\"]=\"circle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "G=F.to_graph_tool(vertex_attributes={\"color\":\"vector<float>\",\"size\":\"int\",\"shape\":\"string\"},edge_attributes={\"color\":\"vector<float>\"})\n",
    "gt.graph_draw(G, vertex_fill_color=G.vertex_properties[\"color\"],vertex_shape=G.vertex_properties[\"shape\"],vertex_size=G.vertex_properties[\"size\"],edge_color=G.edge_properties[\"color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a list of nodes, give distances between nodes\n",
    "def calcDistBtwnNodes(graph,chosenNodeNames):\n",
    "    return graph.shortest_paths_dijkstra(source=chosenNodeNames, target=chosenNodeNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matPCC=calcDistBtwnNodes(F,workerIds)\n",
    "PCCList=[]\n",
    "for sublist in matPCC:\n",
    "    PCCList.extend(sublist)\n",
    "maxDist=max(PCCList)\n",
    "PCCSelf=[]\n",
    "PCCSameCluster=[]\n",
    "PCCOtherCluster=[]\n",
    "\n",
    "for i, dists in enumerate(matPCC):\n",
    "    source=F.vs.find(workerIds[i])\n",
    "    for j in range(i+1):\n",
    "        target=F.vs.find(workerIds[j])\n",
    "        #print(source,target)\n",
    "        if source[\"name\"]==target[\"name\"]:\n",
    "            PCCSelf.append(matPCC[i][j])\n",
    "        elif source[\"cluster\"]==target[\"cluster\"]:\n",
    "            PCCSameCluster.append(matPCC[i][j])\n",
    "        else:\n",
    "            PCCOtherCluster.append(matPCC[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data=[PCCSelf,PCCSameCluster,PCCOtherCluster]\n",
    "colors=[\"grey\",\"red\",\"blue\"]\n",
    "labels=[\"self\",\"same community\",\"other community\"]\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 100, 1) # fixed bin size\n",
    "\n",
    "plt.xlim([0, maxDist+1])\n",
    "plt.yscale(\"log\")\n",
    "plt.hist(data, bins=bins, color=colors, label=labels, stacked=True)\n",
    "plt.title('Shortest path lengths between workers')\n",
    "plt.xlabel('Shortest path length')\n",
    "plt.ylabel('Count of workers')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(\"Same\",Counter(PCCSameCluster))\n",
    "print(\"Other\",Counter(PCCOtherCluster))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/histograms-and-density-plots-in-python-f6bda88f5ac0\n",
    "Stacked bars to see same and different community node distances\n",
    "\n",
    "https://www.w3resource.com/graphics/matplotlib/barchart/matplotlib-barchart-exercise-16.php\n",
    "to annotate values on stacked bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the greater the value, the better\n",
    "print(sum(PCCList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max distance between nodes (graph diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F.diameter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distances inter-nodes intra-clusters (cluster diameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs=partition.subgraphs()\n",
    "diameters=list([subgraph.diameter() for subgraph in subgraphs])\n",
    "plt.plot(diameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radii=list([subgraph.radius() for subgraph in subgraphs])\n",
    "plt.plot(radii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricities=list([subgraph.eccentricity() for subgraph in subgraphs])\n",
    "print(eccentricities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes per community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "nbClusters=len(Counter(F.vs[\"cluster\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, nbClusters+1, 1)\n",
    "plt.hist(F.vs[\"cluster\"], bins=bins)\n",
    "plt.title('Number of nodes in communities')\n",
    "plt.xlabel('Community')\n",
    "plt.ylabel('Count of nodes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workers per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data=[F.vs.find(worker)[\"cluster\"] for worker in workerIds]\n",
    "bins = np.arange(0, nbClusters+1, 1)\n",
    "plt.hist(data, bins=bins)\n",
    "plt.title('Number of workers in communities')\n",
    "plt.xlabel('Community')\n",
    "plt.ylabel('Count of workers')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster diameter based worker count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameters=[subgraph.diameter() for subgraph in partition.subgraphs()]\n",
    "\n",
    "workers=[diameter//2+diameter%2 for diameter in diameters]\n",
    "assignedWorkers=sum(workers)\n",
    "print(assignedWorkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
