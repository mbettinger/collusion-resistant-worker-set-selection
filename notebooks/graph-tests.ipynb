{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool.all as gt\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvGraphsPath=\"../graphs/csv/\"\n",
    "csvGraphFileName=\"facebook_combined.csv\"\n",
    "csvGraphFilePath=csvGraphsPath+csvGraphFileName\n",
    "fbGraph=gt.load_graph_from_csv(csvGraphFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F=ig.Graph.Read(\"../graphs/ncol/facebook_combined.txt\",format=\"ncol\").as_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbWorkers=31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "class TimeoutException(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deadline(timeout, *args):\n",
    "    \"\"\"is a the decotator name with the timeout parameter in second\"\"\"\n",
    "    def decorate(f):\n",
    "        \"\"\" the decorator creation \"\"\"\n",
    "        def handler(signum, frame):\n",
    "            \"\"\" the handler for the timeout \"\"\"\n",
    "            raise TimeoutException() #when the signal have been handle raise the exception\n",
    "\n",
    "        def new_f(*args):\n",
    "            \"\"\" the initiation of the handler, \n",
    "            the lauch of the function and the end of it\"\"\"\n",
    "            signal.signal(signal.SIGALRM, handler) #link the SIGALRM signal to the handler\n",
    "            signal.alarm(timeout) #create an alarm of timeout second\n",
    "            res = f(*args) #lauch the decorate function with this parameter\n",
    "            signal.alarm(0) #reinitiate the alarm\n",
    "            return res #return the return value of the fonction\n",
    "    \n",
    "        new_f.__name__ = f.__name__\n",
    "        return new_f\n",
    "    return decorate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoratorFunctionWithArguments(arg1, arg2, arg3):\n",
    "    def wrap(f):\n",
    "        print(\"Inside wrap()\")\n",
    "        def wrapped_f(*args):\n",
    "            print(\"Inside wrapped_f()\")\n",
    "            print(\"Decorator arguments:\", arg1, arg2, arg3)\n",
    "            res=f(*args)\n",
    "            print(\"After f(*args)\")\n",
    "            return res\n",
    "        return wrapped_f\n",
    "    return wrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import math\n",
    "def colorDistribution(nbColors):\n",
    "    assert nbColors>=1\n",
    "    base=13\n",
    "    maxValues=4\n",
    "    nbValues=math.ceil(nbColors/base)\n",
    "    if nbValues==1:\n",
    "        values=[1]\n",
    "    else:\n",
    "        denominatorV=min(maxValues,nbValues)\n",
    "        values=[min(1,0.5+0.5*v/(denominatorV-1)) for v in range(denominatorV)]\n",
    "\n",
    "    if nbColors==1:\n",
    "        hues=[0]\n",
    "    else:\n",
    "        denominatorH=min(base,nbColors)\n",
    "        hues=[h/(denominatorH) for h in range(denominatorH)]\n",
    "    sats=[1]\n",
    "    nbSat=1\n",
    "    if nbValues>maxValues:\n",
    "        nbSat=math.ceil(nbColors/(denominatorH*denominatorV))\n",
    "        sats=[min(1,0.4+0.5*s/(nbSat-1)) for s in range(nbSat)]\n",
    "    HSVs=[]\n",
    "    \n",
    "    for value in values[::-1]:\n",
    "        for i in range(len(hues)):\n",
    "            for sat in sats[::-1]:\n",
    "                if i%2==0:\n",
    "                    HSVs.append((hues[i//2],sat,value))\n",
    "                else:\n",
    "                    HSVs.append((hues[-i//2],sat,value))\n",
    "\n",
    "    colours = [colorsys.hsv_to_rgb(hue, sat, value) for hue,sat,value in HSVs]\n",
    "    return colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCommunities(graph):\n",
    "    detect_communities=[graph.community_multilevel,\n",
    "                        graph.community_label_propagation,\n",
    "                        graph.community_leading_eigenvector]\n",
    "    \n",
    "    partition=detect_communities[0]()\n",
    "    \n",
    "    colours=colorDistribution(len(partition))\n",
    "\n",
    "    for idx, c in enumerate(partition):\n",
    "        color=colours[idx]\n",
    "        for v in c:\n",
    "            partition.graph.vs[v][\"color\"]=color\n",
    "            partition.graph.vs[v][\"cluster\"]=idx\n",
    "            for e in partition.graph.incident(v):\n",
    "                ed=partition.graph.es[e]\n",
    "                if ed.source in c and ed.target in c:\n",
    "                    ed[\"color\"]=[0.,0.,0.,1.]\n",
    "                else:\n",
    "                    ed[\"color\"]=[0.5,0.5,0.5,1.]\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseVertex(graph):\n",
    "    assert len(graph.vs)>0, \"Can't choose a vertex in an empty graph.\" \n",
    "    node=None\n",
    "    minBetweenness = -1\n",
    "    for idx, betweenness in enumerate(graph.betweenness()):\n",
    "        if betweenness < minBetweenness or minBetweenness == -1 :\n",
    "            node= idx\n",
    "        if betweenness==0:\n",
    "            break\n",
    "    assert node is not None\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanceCrit(value):\n",
    "    outputs=[0,0,5,10]\n",
    "    if value>=len(outputs):\n",
    "        return outputs[-1]\n",
    "    return outputs[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxMinPCCNodeSelection(dictPCC):\n",
    "    assert dictPCC!={}\n",
    "    chosenId=None\n",
    "    nbNodes=len(list(dictPCC.values())[0])\n",
    "    maxDist=-1\n",
    "    maxSumDist=-1\n",
    "    maxDistNode=None\n",
    "    for nodeId in range(nbNodes):\n",
    "        if nodeId not in dictPCC.keys():\n",
    "            minDist=-1\n",
    "            minDistNode=nodeId\n",
    "            for chosenNode in dictPCC.keys():\n",
    "                if minDist==-1 or dictPCC[chosenNode][nodeId]<minDist:\n",
    "                    minDist=dictPCC[chosenNode][nodeId]\n",
    "            #if equivalent on criterion 1, calculate criterion 2\n",
    "            sumDist=-1\n",
    "            if maxSumDist==-1 or minDist==maxDist:\n",
    "                #sumDist=sum([dictPCC[chosenNode][nodeId] for chosenNode in dictPCC.keys()])\n",
    "                #sumDist=random()\n",
    "                sumDist=sum([distanceCrit(dictPCC[chosenNode][nodeId]) for chosenNode in dictPCC.keys()])\n",
    "            #if better crit1 or equal crit1 but better crit2\n",
    "            if minDist>maxDist or (minDist==maxDist and sumDist>maxSumDist):\n",
    "                maxDist=minDist\n",
    "                maxDistNode=minDistNode\n",
    "                maxSumDist=sumDist\n",
    "    chosenId=maxDistNode\n",
    "    return chosenId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxShortestPathNodesSelection(graph,nbNodes,boundaryNodes=[]):\n",
    "    assert len(graph.vs)-len(boundaryNodes)>= nbNodes, \"{} {} {}\".format(len(graph.vs),nbNodes,len(boundaryNodes))\n",
    "    if boundaryNodes==[]:\n",
    "        chosenIds=[chooseVertex(graph)]\n",
    "    else:\n",
    "        chosenIds=boundaryNodes.copy()\n",
    "    #BFS initial des noeuds dans chosenIds\n",
    "    matPCC=graph.shortest_paths_dijkstra(chosenIds)\n",
    "    dictPCC={chosenId:matPCC[idxPCC] for idxPCC,chosenId in enumerate(chosenIds)}\n",
    "    \n",
    "    #nbNodes fois\n",
    "    while len(chosenIds)-len(boundaryNodes)<nbNodes:\n",
    "        chosenNodeId=maxMinPCCNodeSelection(dictPCC)\n",
    "\n",
    "        #BFS du nouveau noeud\n",
    "        dictPCC[chosenNodeId]=graph.shortest_paths_dijkstra(chosenNodeId)[0] #On prend la ligne de la matrice qui correspond au noeud\n",
    "        chosenIds.append(chosenNodeId)\n",
    "    assert len(chosenIds)==len(boundaryNodes)+nbNodes\n",
    "    return chosenIds[len(boundaryNodes):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineBoundary(graph, clusterVertices, clusterId):\n",
    "    boundaryVertices=set()\n",
    "    for v in clusterVertices: #Trouver les successeurs hors cluster aka les noeuds frontaliers au cluster\n",
    "        boundaryVertices.update([bv for bv in v.successors() if bv[\"cluster\"]!=clusterId])\n",
    "    boundaryVertices=list(boundaryVertices)\n",
    "    \n",
    "    return boundaryVertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBoundedCluster(boundedCluster,workerIds,clusterId):\n",
    "    for node in boundedCluster.vs:\n",
    "        if node[\"name\"]in boundedCluster.vs[workerIds][\"name\"]:\n",
    "            node[\"shape\"]=\"triangle\"\n",
    "\n",
    "    ig.plot(boundedCluster,\"../graphs/img/cluster{}.png\".format(clusterId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignWorkersInCommunity(graph,clusterGraph,clusterId):\n",
    "    clusterVertices=[v for v in graph.vs if v[\"cluster\"]==clusterId]\n",
    "    \n",
    "    boundaryVertices=[]\n",
    "    boundaryVertices=defineBoundary(graph,clusterVertices,clusterId)\n",
    "    \n",
    "    boundedCluster=graph.induced_subgraph(boundaryVertices+clusterVertices)\n",
    "    \n",
    "    #Réidentification des noeuds du graphe global vers le sous-graphe\n",
    "    #clusterVertices=[boundedCluster.vs.find(v[\"name\"]) for v in clusterVertices]\n",
    "    boundaryVertices=[boundedCluster.vs.find(v[\"name\"]) for v in boundaryVertices]\n",
    "    boundaryVerticesIds=[bv.index for bv in boundaryVertices]\n",
    "    \n",
    "    workerIds=maxShortestPathNodesSelection(boundedCluster,clusterGraph.vs[clusterId][\"nb_workers\"],boundaryVerticesIds)\n",
    "    \n",
    "    #drawBoundedCluster(boundedCluster,workerIds,clusterId)\n",
    "    \n",
    "    return boundedCluster.vs[workerIds][\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import scipy\n",
    "import pylab\n",
    "import scipy.cluster.hierarchy as sch\n",
    "def biggestOnesSquare(srcDF):\n",
    "    matPCC=srcDF.to_numpy()\n",
    "    # Generate features and distance matrix.\n",
    "    D = scipy.zeros([len(matPCC),len(matPCC)])\n",
    "    for i in range(len(matPCC)):\n",
    "        for j in range(len(matPCC)):\n",
    "            D[i,j] = matPCC[i][j]\n",
    "\n",
    "    # Compute and plot dendrogram.\n",
    "    fig = pylab.figure()\n",
    "    axdendro = fig.add_axes([0.09,0.1,0.2,0.8])\n",
    "    Y = sch.linkage(D, method='complete')\n",
    "    Z = sch.dendrogram(Y, orientation='right')\n",
    "    axdendro.set_xticks([])\n",
    "    axdendro.set_yticks([])\n",
    "\n",
    "    # Plot distance matrix.\n",
    "    axmatrix = fig.add_axes([0.3,0.1,0.6,0.8])\n",
    "    index = Z['leaves']\n",
    "    D = D[index,:]\n",
    "    D = D[:,index]\n",
    "    im = axmatrix.matshow(D, aspect='auto', origin='lower')\n",
    "    axmatrix.set_xticks([])\n",
    "    axmatrix.set_yticks([])\n",
    "\n",
    "    # Plot colorbar.\n",
    "    axcolor = fig.add_axes([0.91,0.1,0.02,0.8])\n",
    "    pylab.colorbar(im, cax=axcolor)\n",
    "\n",
    "    # Display and save figure.\n",
    "    fig.show()\n",
    "    fig.savefig('dendrogram.png')\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atLeastNWorkers(minWorkers):\n",
    "    def wrap(f):\n",
    "        def wrapped_f(graph,partition,clusterGraph,nWorkers):\n",
    "            #Chaque cluster aura au moins un worker en lui\n",
    "            for cluster in clusterGraph.vs:\n",
    "                cluster[\"nb_workers\"]=minWorkers\n",
    "\n",
    "            #Attribuer le nombre de workers réel\n",
    "            remainingWorkers=nWorkers-len(clusterGraph.vs)\n",
    "            res=f(graph,partition,clusterGraph,remainingWorkers)\n",
    "            return res\n",
    "        return wrapped_f\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def subgraphCapacity(graph, minDist):\n",
    "    nodes=graph.vs\n",
    "    candidates=set()\n",
    "    matPCC=graph.shortest_paths_dijkstra()\n",
    "\n",
    "    dfPCC=pd.DataFrame(matPCC,nodes[\"name\"],nodes[\"name\"])\n",
    "    #print((dfPCC > minDist).values)\n",
    "    g = ig.Graph.Adjacency((dfPCC >= minDist).values.tolist()).as_undirected()\n",
    "    g.vs[\"name\"]=nodes[\"name\"]\n",
    "    #ig.plot(g,\"../graphs/img/graph.png\")\n",
    "    #print(g)\n",
    "    try:\n",
    "        cliques=deadline(10)(g.largest_cliques)()\n",
    "        candidates=[nodes[idx][\"name\"] for idx in cliques[0]]\n",
    "        \n",
    "        print(\"n_clq\",len(cliques),\"l_clq\", len(cliques[0]),\"a clq\", cliques[0])\n",
    "        print(\"len(c)\",len(candidates),\"len(n)\",len(nodes))\n",
    "        yield candidates\n",
    "    except TimeoutException:\n",
    "        print(\"Timeout\")\n",
    "        candidates=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def capacityBasedWorkerAssignment(graph,partition,clusterGraph,nWorkers):\n",
    "    assignedWorkers=0\n",
    "    nbClusters=len(partition)\n",
    "    candidatesDict={clusterId:{} for clusterId in range(nbClusters)}\n",
    "    diameters=[subgraph.diameter() for subgraph in partition.subgraphs()]\n",
    "    \n",
    "    cliques=[idx for idx in range(nbClusters) if diameters[idx]==1]\n",
    "    \n",
    "    for clusterId, subgraph in enumerate(partition.subgraphs()):\n",
    "        diameter=diameters[clusterId]\n",
    "        radius=int(subgraph.radius())\n",
    "        \n",
    "        print(\"d\",diameter,\"r\", radius)\n",
    "        if clusterId not in cliques:\n",
    "            for eccentricity in reversed(list(range(2,diameter+1))):#if diameter is 1 => clique => only one worker should be placed\n",
    "                print(\"e\",eccentricity)\n",
    "                candidatesDict[clusterId][eccentricity]=subgraphCapacity(subgraph,eccentricity)\n",
    "        else:\n",
    "            candidatesDict[clusterId][1]=None\n",
    "            clusterGraph[clusterId][\"nb_workers\"]=1 #because all nodes know each other\n",
    "    print(candidatesDict)\n",
    "    \n",
    "    betweenness=clusterGraph.betweenness()\n",
    "    \n",
    "    sortedBtwnsIdx=sorted(range(len(clusterGraph.vs)), key=lambda k: (diameters[k],betweenness[k]), reverse=True)\n",
    "    print(sortedBtwnsIdx)\n",
    "    \n",
    "    eccIdx=diameters.copy()\n",
    "    for idx in range(nbClusters):\n",
    "        #candidatesDict[idx][eccIdx[idx]]=next(candidatesDict[idx][eccIdx[idx]],None)\n",
    "        for key in candidatesDict[idx].keys():\n",
    "            candidatesDict[idx][key]=next(candidatesDict[idx][key],None)\n",
    "            #None values happen when the search space is vast, i.e close to the initial graph, when minDist is low (2 or 3)\n",
    "            #This means there isn't a particular need to find optimal values if nodes are that close, but if we find a solution anyway, good for us.\n",
    "            #If we didn't find a solution, we'll use approximation functions later\n",
    "\n",
    "    print(candidatesDict)\n",
    "    #Now we have a certain amount of clusters with distantiated nodes and may have clusters which timed out on the search\n",
    "    #Those timed out clusters will receive workers through other methods\n",
    "    \n",
    "    nbCurrentWorkers={(minDist,maxDist):sum([len(candidatesDict[idx][min(eccIdx[idx],maxDist)]) \n",
    "                                   for idx in range(nbClusters) \n",
    "                                   if candidatesDict[idx][min(eccIdx[idx],maxDist)] is not None and eccIdx[idx]>=minDist]) \n",
    "                      for (minDist,maxDist) in itertools.product(range(2, max(diameters)+1),range(2, max(diameters)+1))\n",
    "                         if minDist<=maxDist}\n",
    "    print(\"nbCurWrks\",nbCurrentWorkers)\n",
    "    \n",
    "    unsolvedClusters={(minDist,maxDist):[cluster for cluster in range(nbClusters)\n",
    "                                            if eccIdx[cluster]<minDist \n",
    "                                            or all([candidatesDict[cluster][ecc] is None \n",
    "                                                    for ecc in range(minDist,min(eccIdx[cluster],maxDist)+1)])\n",
    "                                        ] for (minDist,maxDist) in nbCurrentWorkers.keys()}\n",
    "    print(\"unsolved\",unsolvedClusters)\n",
    "    \n",
    "    unsolvedClustersWorkers={(minDist,maxDist):sum([1+diameters[cluster]//2\n",
    "                                                 for cluster in unsolvedClusters[(minDist,maxDist)]])\n",
    "                                 for (minDist,maxDist) in nbCurrentWorkers.keys()}\n",
    "    print(\"unsolvedNbWorkers\",unsolvedClustersWorkers)\n",
    "    \n",
    "    totalWorkersInCliques=len(cliques)\n",
    "    \n",
    "    maxMinDistEnoughWorkers=1\n",
    "    counter=0\n",
    "    while maxMinDistEnoughWorkers==1:\n",
    "        counter+=1\n",
    "        maxMinDistEnoughWorkers=max([minDist for (minDist,maxDist),nbPlacedWorkers in nbCurrentWorkers.items() \n",
    "                                         if nbPlacedWorkers \n",
    "                                             + min(counter*len(unsolvedClusters[(minDist,maxDist)]),\n",
    "                                                   unsolvedClustersWorkers[(minDist,maxDist)]) \n",
    "                                             + totalWorkersInCliques\n",
    "                                             >=nWorkers],\n",
    "                                    default=1)\n",
    "    print(\"nbFoisLen\",counter)\n",
    "    \n",
    "    if maxMinDistEnoughWorkers==1:\n",
    "        print(\"We haven't found a solution *yet*, might as well abort...\")\n",
    "    else:\n",
    "        print(\"Best minDist: \",maxMinDistEnoughWorkers)\n",
    "        maxMaxDistEnoughWorkers=max([maxDist for (minDist,maxDist),nbPlacedWorkers in nbCurrentWorkers.items() \n",
    "                                     if minDist==maxMinDistEnoughWorkers and \n",
    "                                         nbPlacedWorkers + unsolvedClustersWorkers[(minDist,maxDist)] + totalWorkersInCliques\n",
    "                                         >=nWorkers ])\n",
    "        minMax=(maxMinDistEnoughWorkers,maxMaxDistEnoughWorkers)\n",
    "        print(\"Best maxDist: \",maxMaxDistEnoughWorkers)\n",
    "        print(\"Workers to be assigned: \",nWorkers)\n",
    "        print(\"Workers in clique communities: \",totalWorkersInCliques)\n",
    "        print(\"Workers in unsolved communities: \",unsolvedClustersWorkers[minMax])\n",
    "        newEccIdx=[min(idx,maxMaxDistEnoughWorkers) for idx in eccIdx]\n",
    "        assignedSolvedWorkers={cIdx:{\"minDist\":newEccIdx[cIdx],\n",
    "                                     \"workers\":candidatesDict[cIdx][newEccIdx[cIdx]]} \n",
    "                                for cIdx in range(nbClusters) \n",
    "                                if newEccIdx[cIdx]>= maxMinDistEnoughWorkers \n",
    "                                       and candidatesDict[cIdx][newEccIdx[cIdx]] is not None}\n",
    "        print(\"Number of workers in solved communities: \",sum([len(value) for value in assignedSolvedWorkers.values()]))\n",
    "        print(\"Workers in solved communities: \",assignedSolvedWorkers)\n",
    "        clusterIdsByMinDist=sorted(assignedSolvedWorkers.keys(), key=lambda k: assignedSolvedWorkers[k][\"minDist\"], reverse=False)\n",
    "        #Check if you can assign 1 worker to clique (1 per clq) and unsolved clusters and complete with solved cluster workers\n",
    "        workersToAssignInSolvedClusters=nWorkers-totalWorkersInCliques-unsolvedClustersWorkers[minMax]\n",
    "        \n",
    "        for cluster in cliques:\n",
    "            clusterGraph.vs[cluster][\"nb_workers\"]=1\n",
    "        assignedWorkers+=len(cliques)\n",
    "            \n",
    "        print(\"w\",workersToAssignInSolvedClusters,nbCurrentWorkers[minMax])\n",
    "        if workersToAssignInSolvedClusters<nbCurrentWorkers[minMax]:\n",
    "            #Unsolved clusters get 1 worker\n",
    "            for cluster in unsolvedClusters[minMax]:\n",
    "                clusterGraph.vs[cluster][\"nb_workers\"]=1\n",
    "            assignedWorkers+=len(unsolvedClusters[minMax])\n",
    "            \n",
    "            #We need to remove some workers in the solved clusters\n",
    "            #We first do as if we put all of them in\n",
    "            assignedWorkers+=nbCurrentWorkers[minMax]\n",
    "            for cluster in assignedSolvedWorkers.keys():\n",
    "                #We keep the exact workers lists in solved clusters\n",
    "                clusterGraph.vs[cluster][\"nb_workers\"]=len(assignedSolvedWorkers[cluster][\"workers\"])\n",
    "            #Then we remove excess workers\n",
    "            clustersPerDist={currentDist:[cluster for cluster,infos in assignedSolvedWorkers.items() \n",
    "                                          if infos[\"minDist\"]==currentDist]\n",
    "                                for currentDist in reversed(list(range(minMax[0],minMax[1]+1)))\n",
    "                            }\n",
    "            print(\"-1\",assignedWorkers)\n",
    "            while assignedWorkers>nbWorkers:\n",
    "                for clusters in clustersPerDist.values():\n",
    "                    succeeded=True\n",
    "                    while(succeeded):\n",
    "                        succeeded=False\n",
    "                        for cluster in clusters:\n",
    "                            if clusterGraph.vs[cluster][\"nb_workers\"]>2:\n",
    "                                assignedSolvedWorkers[cluster][\"workers\"].pop()\n",
    "                                assignedWorkers-=1\n",
    "                                succeeded=True\n",
    "                                print(\"0\",assignedWorkers)\n",
    "                            print(\"1\",assignedWorkers)\n",
    "                            if assignedWorkers==nbWorkers:\n",
    "                                succeeded=True\n",
    "                                break\n",
    "                            print(\"1a\",assignedWorkers)\n",
    "                        print(\"2\",assignedWorkers)\n",
    "                    print(\"3\",assignedWorkers)\n",
    "                    if assignedWorkers==nbWorkers:\n",
    "                        break\n",
    "                print(\"4\",assignedWorkers)\n",
    "            print(\"5\",assignedWorkers)\n",
    "        else:#We know there is enough room in unsolved clusters\n",
    "            for cluster in assignedSolvedWorkers.keys():\n",
    "                #We keep the exact workers lists in solved clusters\n",
    "                clusterGraph.vs[cluster][\"nb_workers\"]=len(assignedSolvedWorkers[cluster][\"workers\"])\n",
    "            assignedWorkers+=nbCurrentWorkers[minMax]\n",
    "            #We assign the unsolved cluster workers with the diameter based method\n",
    "            remainingWorkers=nbWorkers-assignedWorkers\n",
    "            \n",
    "            clusterGraph=diameterWorkerAssignment(graph,partition,clusterGraph,remainingWorkers,unsolvedClusters[minMax])\n",
    "            assignedWorkers+=remainingWorkers\n",
    "            \n",
    "    assert all([cluster[\"nb_workers\"]>=1 for cluster in clusterGraph.vs]), \"{}\".format(clusterGraph.vs[\"nb_workers\"])\n",
    "    assert assignedWorkers==nWorkers, \"Only {} assigned workers out of {}\".format(assignedWorkers,nWorkers)\n",
    "    clustersToFill=[*unsolvedClusters[minMax],*cliques]\n",
    "    return [],clusterGraph,clustersToFill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@atLeastNWorkers(1)\n",
    "def sizeOrderedRoundRobinWorkerAssignement(graph,partition,clusterGraph,remainingWorkers):\n",
    "    graphSize=len(graph.vs)\n",
    "    relativeSizes=[len(partition.subgraph(int(cluster[\"name\"][1:])).vs)/graphSize for cluster in clusterGraph.vs]\n",
    "\n",
    "    sortedIdxPerSize=sorted(range(len(relativeSizes)), key=lambda k: relativeSizes[k], reverse=True)\n",
    "    sortedSizes=sorted(relativeSizes)\n",
    "\n",
    "    #Round Robin par ordre de taille des clusters\n",
    "    currentCluster=0\n",
    "    while remainingWorkers>0:\n",
    "        currentSortedCluster=sortedIdxPerSize[currentCluster]\n",
    "        if clusterGraph.vs[currentSortedCluster][\"nb_workers\"]<len(partition.subgraph(currentSortedCluster).vs):\n",
    "            clusterGraph.vs[currentSortedCluster][\"nb_workers\"]+=1\n",
    "            remainingWorkers-=1\n",
    "        currentCluster+=1\n",
    "        if currentCluster>=len(clusterGraph.vs):\n",
    "            currentCluster=0\n",
    "    return [],clusterGraph, range(len(partition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@atLeastNWorkers(1)\n",
    "def sizeProRataWorkerAssignement(graph,partition,clusterGraph,remainingWorkers):\n",
    "    graphSize=len(graph.vs)\n",
    "    relativeSizes=[len(partition.subgraph(int(cluster[\"name\"][1:])).vs)/graphSize for cluster in clusterGraph.vs]\n",
    "\n",
    "    proRataWorkers=[remainingWorkers*size for size in relativeSizes]\n",
    "    intProRataWorkers=[int(prw) for prw in proRataWorkers]\n",
    "    \n",
    "    assignedWorkers=sum(intProRataWorkers)\n",
    "    if assignedWorkers < remainingWorkers:\n",
    "        remainingProRataWorkers=[prw - prw//1 for prw in proRataWorkers]\n",
    "        sortedIdx=sorted(range(len(remainingProRataWorkers)), key=lambda k: remainingProRataWorkers[k], reverse=True)\n",
    "\n",
    "        for i in range(remainingWorkers-assignedWorkers):\n",
    "            intProRataWorkers[sortedIdx[i]]+=1\n",
    "            assignedWorkers+=1\n",
    "        \n",
    "    for idx, cluster in enumerate(clusterGraph.vs):\n",
    "        cluster[\"nb_workers\"]+=intProRataWorkers[idx]\n",
    "    \n",
    "    assert assignedWorkers==remainingWorkers, \"Only {} assigned workers out of {}\".format(assignedWorkers,remainingWorkers)\n",
    "    return [],clusterGraph, range(len(partition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@atLeastNWorkers(1)\n",
    "def diameterProRataWorkerAssignement(graph,partition,clusterGraph,remainingWorkers):\n",
    "\n",
    "    diameters=[subgraph.diameter() for subgraph in partition.subgraphs()]\n",
    "    sumDiameters=sum(diameters)\n",
    "    \n",
    "    proRataWorkers=[remainingWorkers*diameter/sumDiameters for diameter in diameters]\n",
    "    intProRataWorkers=[int(prw) for prw in proRataWorkers]\n",
    "    \n",
    "    assignedWorkers=sum(intProRataWorkers)\n",
    "    if assignedWorkers < remainingWorkers:\n",
    "        remainingProRataWorkers=[prw - prw//1 for prw in proRataWorkers]\n",
    "        sortedIdx=sorted(range(len(remainingProRataWorkers)), key=lambda k: remainingProRataWorkers[k], reverse=True)\n",
    "\n",
    "        for i in range(remainingWorkers-assignedWorkers):\n",
    "            intProRataWorkers[sortedIdx[i]]+=1\n",
    "            assignedWorkers+=1\n",
    "        \n",
    "    for idx, cluster in enumerate(clusterGraph.vs):\n",
    "        cluster[\"nb_workers\"]+=intProRataWorkers[idx]\n",
    "    \n",
    "    assert assignedWorkers==remainingWorkers, \"Only {} assigned workers out of {}\".format(assignedWorkers,remainingWorkers)\n",
    "    return [],clusterGraph, range(len(partition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diameterWorkerAssignment(graph,partition,clusterGraph,remainingWorkers,clustersToFill=None):\n",
    "    diameters=[subgraph.diameter() for subgraph in partition.subgraphs()]\n",
    "    \n",
    "    if clustersToFill is None:\n",
    "        clustersToFill=range(len(clusterGraph.vs))\n",
    "    \n",
    "    workers=[1+diameter//2 for diameter in diameters]\n",
    "    assignedWorkers=sum([nb for idx,nb in enumerate(workers) if idx in clustersToFill])\n",
    "    for idx in clustersToFill:\n",
    "        clusterGraph.vs[idx][\"nb_workers\"]+=workers[idx]\n",
    "    \n",
    "    while assignedWorkers>remainingWorkers:\n",
    "        sortedIdx=sorted(clustersToFill, key=lambda k: workers[k], reverse=True)\n",
    "\n",
    "        for i in range(assignedWorkers-remainingWorkers):\n",
    "            if clusterGraph.vs[sortedIdx[i%len(sortedIdx)]][\"nb_workers\"]>1:\n",
    "                clusterGraph.vs[sortedIdx[i%len(sortedIdx)]][\"nb_workers\"]-=1\n",
    "                assignedWorkers-=1\n",
    "    \n",
    "    if assignedWorkers<remainingWorkers:\n",
    "        clusterGraph=sizeOrderedRoundRobinWorkerAssignement(graph,partition,clusterGraph,remainingWorkers-assignedWorkers)\n",
    "        assignedWorkers=remainingWorkers\n",
    "    \n",
    "    assert assignedWorkers==remainingWorkers, \"Only {} assigned workers out of {}\".format(assignedWorkers,remainingWorkers)\n",
    "    return [],clusterGraph,clustersToFill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignWorkers(graph,nWorkers):\n",
    "    assert nWorkers>=0, \"{} workers to assign: Number of workers to assign must be positive or zero\".format(nWorkers)\n",
    "    assert len(graph.vs)>=nWorkers, \"{} workers to assign on {} nodes: Can't assign more workers than there are vertices\".format(nWorkers,len(graph.vs))\n",
    "    partition=findCommunities(graph)\n",
    "    \n",
    "    clusterGraph=partition.cluster_graph(\"first\")\n",
    "\n",
    "    for idx, cluster in enumerate(clusterGraph.vs):\n",
    "        cluster[\"name\"]=\"C{}\".format(idx)\n",
    "\n",
    "    workerIds=[]\n",
    "    clusterIds=[]\n",
    "    if len(partition)<nWorkers:        \n",
    "        workerAssignment=[sizeProRataWorkerAssignement,\n",
    "                          sizeOrderedRoundRobinWorkerAssignement,\n",
    "                          diameterProRataWorkerAssignement,\n",
    "                          diameterWorkerAssignment,\n",
    "                          capacityBasedWorkerAssignment,\n",
    "                          #subpartitioning\n",
    "                         ]\n",
    "\n",
    "        %time workerIds,clusterGraph,clusterIds=workerAssignment[4](graph, partition,clusterGraph, nWorkers)\n",
    "        \n",
    "    elif len(partition)==nWorkers:\n",
    "        #1cluster/1worker\n",
    "        for cluster in clusterGraph.vs:\n",
    "            cluster[\"nb_workers\"]=1\n",
    "        clusterIds=range(len(partition))\n",
    "    else:\n",
    "        clusterIds=maxShortestPathNodesSelection(clusterGraph,nWorkers)\n",
    "        for cluster in clusterGraph.vs:\n",
    "            if cluster.index in clusterIds:\n",
    "                cluster[\"nb_workers\"]=1\n",
    "            else:\n",
    "                cluster[\"nb_workers\"]=0\n",
    "\n",
    "    #Etape2\n",
    "    #for chaque cluster de workers\n",
    "    #prendre son sous-graphe+ les noeuds frontaliers d'autres clusters, BFS des frontières et Etape1 nb_workers fois\n",
    "    for clusterId in clusterIds:\n",
    "        %time workerIds.extend(assignWorkersInCommunity(graph,clusterGraph,clusterId))\n",
    "    \n",
    "    assert len(workerIds)==nWorkers, \"Assigned {} workers instead of {}\".format(len(workerIds),nWorkers)\n",
    "    return workerIds,partition,clusterGraph,clusterIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d 3 r 2\n",
      "e 3\n",
      "e 2\n",
      "d 5 r 3\n",
      "e 5\n",
      "e 4\n",
      "e 3\n",
      "e 2\n",
      "d 2 r 1\n",
      "e 2\n",
      "d 2 r 1\n",
      "e 2\n",
      "d 4 r 2\n",
      "e 4\n",
      "e 3\n",
      "e 2\n",
      "d 5 r 3\n",
      "e 5\n",
      "e 4\n",
      "e 3\n",
      "e 2\n",
      "d 8 r 4\n",
      "e 8\n",
      "e 7\n",
      "e 6\n",
      "e 5\n",
      "e 4\n",
      "e 3\n",
      "e 2\n",
      "d 3 r 2\n",
      "e 3\n",
      "e 2\n",
      "d 3 r 2\n",
      "e 3\n",
      "e 2\n",
      "d 3 r 2\n",
      "e 3\n",
      "e 2\n",
      "d 2 r 1\n",
      "e 2\n",
      "d 2 r 1\n",
      "e 2\n",
      "d 3 r 2\n",
      "e 3\n",
      "e 2\n",
      "d 5 r 3\n",
      "e 5\n",
      "e 4\n",
      "e 3\n",
      "e 2\n",
      "d 2 r 1\n",
      "e 2\n",
      "d 2 r 2\n",
      "e 2\n",
      "{0: {3: <generator object subgraphCapacity at 0x7f2c08a55120>, 2: <generator object subgraphCapacity at 0x7f2c08833510>}, 1: {5: <generator object subgraphCapacity at 0x7f2c08833cf0>, 4: <generator object subgraphCapacity at 0x7f2c08840890>, 3: <generator object subgraphCapacity at 0x7f2c08840580>, 2: <generator object subgraphCapacity at 0x7f2c07147b30>}, 2: {2: <generator object subgraphCapacity at 0x7f2c071475f0>}, 3: {2: <generator object subgraphCapacity at 0x7f2c07147eb0>}, 4: {4: <generator object subgraphCapacity at 0x7f2c07147e40>, 3: <generator object subgraphCapacity at 0x7f2c07147dd0>, 2: <generator object subgraphCapacity at 0x7f2c0715d270>}, 5: {5: <generator object subgraphCapacity at 0x7f2c0715d6d0>, 4: <generator object subgraphCapacity at 0x7f2c0715d190>, 3: <generator object subgraphCapacity at 0x7f2c0715d120>, 2: <generator object subgraphCapacity at 0x7f2c0715d0b0>}, 6: {8: <generator object subgraphCapacity at 0x7f2c0715d040>, 7: <generator object subgraphCapacity at 0x7f2c0715d900>, 6: <generator object subgraphCapacity at 0x7f2c071647b0>, 5: <generator object subgraphCapacity at 0x7f2c07164820>, 4: <generator object subgraphCapacity at 0x7f2c07164890>, 3: <generator object subgraphCapacity at 0x7f2c07164900>, 2: <generator object subgraphCapacity at 0x7f2c07164970>}, 7: {3: <generator object subgraphCapacity at 0x7f2c071649e0>, 2: <generator object subgraphCapacity at 0x7f2c07164a50>}, 8: {3: <generator object subgraphCapacity at 0x7f2c07164ac0>, 2: <generator object subgraphCapacity at 0x7f2c07164b30>}, 9: {3: <generator object subgraphCapacity at 0x7f2c07164ba0>, 2: <generator object subgraphCapacity at 0x7f2c07164c10>}, 10: {2: <generator object subgraphCapacity at 0x7f2c07164c80>}, 11: {2: <generator object subgraphCapacity at 0x7f2c07164cf0>}, 12: {3: <generator object subgraphCapacity at 0x7f2c07164d60>, 2: <generator object subgraphCapacity at 0x7f2c07164dd0>}, 13: {5: <generator object subgraphCapacity at 0x7f2c07164e40>, 4: <generator object subgraphCapacity at 0x7f2c07164eb0>, 3: <generator object subgraphCapacity at 0x7f2c07164f20>, 2: <generator object subgraphCapacity at 0x7f2c07164f90>}, 14: {2: <generator object subgraphCapacity at 0x7f2c070fb040>}, 15: {2: <generator object subgraphCapacity at 0x7f2c070fb0b0>}}\n",
      "[6, 1, 13, 5, 4, 7, 0, 9, 8, 12, 3, 2, 10, 11, 14, 15]\n",
      "n_clq 668 l_clq 3 a clq (343, 349, 342)\n",
      "len(c) 3 len(n) 350\n",
      "Timeout\n",
      "n_clq 560 l_clq 2 a clq (411, 133)\n",
      "len(c) 2 len(n) 431\n",
      "n_clq 14128 l_clq 4 a clq (135, 80, 127, 429)\n",
      "len(c) 4 len(n) 431\n",
      "Timeout\n",
      "Timeout\n",
      "Timeout\n",
      "Timeout\n",
      "n_clq 487 l_clq 2 a clq (19, 542)\n",
      "len(c) 2 len(n) 543\n",
      "n_clq 4488 l_clq 2 a clq (19, 542)\n",
      "len(c) 2 len(n) 543\n",
      "Timeout\n",
      "n_clq 21 l_clq 2 a clq (281, 279)\n",
      "len(c) 2 len(n) 323\n",
      "n_clq 1 l_clq 7 a clq (198, 60, 257, 115, 18, 243, 279)\n",
      "len(c) 7 len(n) 323\n",
      "Timeout\n",
      "Timeout\n",
      "n_clq 1 l_clq 2 a clq (48, 104)\n",
      "len(c) 2 len(n) 121\n",
      "n_clq 8 l_clq 2 a clq (89, 100)\n",
      "len(c) 2 len(n) 121\n",
      "n_clq 25 l_clq 3 a clq (89, 104, 120)\n",
      "len(c) 3 len(n) 121\n",
      "n_clq 2 l_clq 5 a clq (104, 49, 100, 24, 91)\n",
      "len(c) 5 len(n) 121\n",
      "n_clq 646 l_clq 7 a clq (104, 49, 89, 78, 100, 120, 117)\n",
      "len(c) 7 len(n) 121\n",
      "n_clq 19346 l_clq 11 a clq (104, 64, 89, 49, 63, 78, 100, 92, 85, 26, 118)\n",
      "len(c) 11 len(n) 121\n",
      "Timeout\n",
      "n_clq 1046 l_clq 2 a clq (10, 547)\n",
      "len(c) 2 len(n) 548\n",
      "Timeout\n",
      "n_clq 3 l_clq 2 a clq (47, 64)\n",
      "len(c) 2 len(n) 73\n",
      "n_clq 31 l_clq 10 a clq (47, 48, 46, 49, 61, 26, 39, 40, 29, 51)\n",
      "len(c) 10 len(n) 73\n",
      "n_clq 26 l_clq 3 a clq (162, 225, 163)\n",
      "len(c) 3 len(n) 237\n",
      "Timeout\n",
      "n_clq 15 l_clq 3 a clq (21, 0, 12)\n",
      "len(c) 3 len(n) 25\n",
      "n_clq 192 l_clq 29 a clq (8, 31, 33, 37, 44, 46, 56, 7, 34, 15, 51, 29, 53, 50, 54, 55, 57, 28, 14, 3, 25, 59, 58, 26, 18, 43, 40, 41, 47)\n",
      "len(c) 29 len(n) 60\n",
      "n_clq 4722 l_clq 2 a clq (205, 169)\n",
      "len(c) 2 len(n) 206\n",
      "Timeout\n",
      "n_clq 1 l_clq 2 a clq (142, 217)\n",
      "len(c) 2 len(n) 226\n",
      "n_clq 6 l_clq 4 a clq (217, 201, 103, 225)\n",
      "len(c) 4 len(n) 226\n",
      "n_clq 191 l_clq 10 a clq (217, 76, 142, 211, 167, 108, 107, 136, 58, 225)\n",
      "len(c) 10 len(n) 226\n",
      "Timeout\n",
      "n_clq 3 l_clq 4 a clq (3, 4, 13, 10)\n",
      "len(c) 4 len(n) 19\n",
      "n_clq 6 l_clq 4 a clq (0, 12, 15, 16)\n",
      "len(c) 4 len(n) 19\n",
      "{0: {3: ['V2814', 'V2740', 'V347'], 2: None}, 1: {5: ['V644', 'V1814'], 4: ['V1831', 'V1430', 'V1776', 'V685'], 3: None, 2: None}, 2: {2: None}, 3: {2: None}, 4: {4: ['V1838', 'V3434'], 3: ['V1838', 'V3434'], 2: None}, 5: {5: ['V1759', 'V1755'], 4: ['V1474', 'V1065', 'V1690', 'V1233', 'V945', 'V1646', 'V1755'], 3: None, 2: None}, 6: {8: ['V1252', 'V1760'], 7: ['V1607', 'V1713'], 6: ['V1607', 'V1760', 'V1908'], 5: ['V1760', 'V1254', 'V1713', 'V1057', 'V1629'], 4: ['V1760', 'V1254', 'V1607', 'V1546', 'V1713', 'V1908', 'V1892'], 3: ['V1760', 'V1394', 'V1607', 'V1254', 'V1384', 'V1546', 'V1713', 'V1641', 'V1579', 'V1073', 'V1895'], 2: None}, 7: {3: ['V868', 'V3979'], 2: None}, 8: {3: ['V2013', 'V2626'], 2: ['V2013', 'V2014', 'V2012', 'V2016', 'V2435', 'V2636', 'V1958', 'V1968', 'V2660', 'V2025']}, 9: {3: ['V2442', 'V2613', 'V2443'], 2: None}, 10: {2: ['V665', 'V576', 'V635']}, 11: {2: ['V3984', 'V4008', 'V4010', 'V4015', 'V4022', 'V4024', 'V4035', 'V3983', 'V4012', 'V3992', 'V4029', 'V4006', 'V4032', 'V4028', 'V4033', 'V4034', 'V4036', 'V4005', 'V3991', 'V4011', 'V4002', 'V4038', 'V4037', 'V4003', 'V3995', 'V4021', 'V4018', 'V4019', 'V4025']}, 12: {3: ['V895', 'V855'], 2: None}, 13: {5: ['V3059', 'V3413'], 4: ['V3413', 'V3317', 'V2952', 'V3436'], 3: ['V3413', 'V2899', 'V3059', 'V3388', 'V3143', 'V2963', 'V2961', 'V3044', 'V2852', 'V3436'], 2: None}, 14: {2: ['V2767', 'V2834', 'V3311', 'V3008']}, 15: {2: ['V1924', 'V2466', 'V2513', 'V2515']}}\n",
      "nbCurWrks {(2, 2): 50, (2, 3): 75, (2, 4): 76, (2, 5): 65, (2, 6): 63, (2, 7): 62, (2, 8): 62, (3, 3): 35, (3, 4): 36, (3, 5): 25, (3, 6): 23, (3, 7): 22, (3, 8): 22, (4, 4): 24, (4, 5): 13, (4, 6): 11, (4, 7): 10, (4, 8): 10, (5, 5): 11, (5, 6): 9, (5, 7): 8, (5, 8): 8, (6, 6): 3, (6, 7): 2, (6, 8): 2, (7, 7): 2, (7, 8): 2, (8, 8): 2}\n",
      "unsolved {(2, 2): [0, 1, 2, 3, 4, 5, 6, 7, 9, 12, 13], (2, 3): [1, 2, 3, 5], (2, 4): [2, 3], (2, 5): [2, 3], (2, 6): [2, 3], (2, 7): [2, 3], (2, 8): [2, 3], (3, 3): [1, 2, 3, 5, 10, 11, 14, 15], (3, 4): [2, 3, 10, 11, 14, 15], (3, 5): [2, 3, 10, 11, 14, 15], (3, 6): [2, 3, 10, 11, 14, 15], (3, 7): [2, 3, 10, 11, 14, 15], (3, 8): [2, 3, 10, 11, 14, 15], (4, 4): [0, 2, 3, 7, 8, 9, 10, 11, 12, 14, 15], (4, 5): [0, 2, 3, 7, 8, 9, 10, 11, 12, 14, 15], (4, 6): [0, 2, 3, 7, 8, 9, 10, 11, 12, 14, 15], (4, 7): [0, 2, 3, 7, 8, 9, 10, 11, 12, 14, 15], (4, 8): [0, 2, 3, 7, 8, 9, 10, 11, 12, 14, 15], (5, 5): [0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15], (5, 6): [0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15], (5, 7): [0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15], (5, 8): [0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 14, 15], (6, 6): [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], (6, 7): [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], (6, 8): [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], (7, 7): [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], (7, 8): [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], (8, 8): [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15]}\n",
      "unsolvedNbWorkers {(2, 2): 29, (2, 3): 10, (2, 4): 4, (2, 5): 4, (2, 6): 4, (2, 7): 4, (2, 8): 4, (3, 3): 18, (3, 4): 12, (3, 5): 12, (3, 6): 12, (3, 7): 12, (3, 8): 12, (4, 4): 22, (4, 5): 22, (4, 6): 22, (4, 7): 22, (4, 8): 22, (5, 5): 25, (5, 6): 25, (5, 7): 25, (5, 8): 25, (6, 6): 34, (6, 7): 34, (6, 8): 34, (7, 7): 34, (7, 8): 34, (8, 8): 34}\n",
      "nbFoisLen 1\n",
      "Best minDist:  4\n",
      "Best maxDist:  8\n",
      "Workers to be assigned:  31\n",
      "Workers in clique communities:  0\n",
      "Workers in unsolved communities:  22\n",
      "Number of workers in solved communities:  10\n",
      "Workers in solved communities:  {1: {'minDist': 5, 'workers': ['V644', 'V1814']}, 4: {'minDist': 4, 'workers': ['V1838', 'V3434']}, 5: {'minDist': 5, 'workers': ['V1759', 'V1755']}, 6: {'minDist': 8, 'workers': ['V1252', 'V1760']}, 13: {'minDist': 5, 'workers': ['V3059', 'V3413']}}\n",
      "w 9 10\n",
      "-1 21\n",
      "5 21\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Only 21 assigned workers out of 31",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-24135d0ff2e6>\u001b[0m in \u001b[0;36mcapacityBasedWorkerAssignment\u001b[0;34m(graph, partition, clusterGraph, nWorkers)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nb_workers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclusterGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusterGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nb_workers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0massignedWorkers\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnWorkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Only {} assigned workers out of {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massignedWorkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnWorkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0mclustersToFill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munsolvedClusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mminMax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcliques\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclusterGraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclustersToFill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Only 21 assigned workers out of 31"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Assigned 0 workers instead of 31",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-7b66f3908505>\u001b[0m in \u001b[0;36massignWorkers\u001b[0;34m(graph, nWorkers)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'workerIds.extend(assignWorkersInCommunity(graph,clusterGraph,clusterId))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkerIds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnWorkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Assigned {} workers instead of {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkerIds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnWorkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mworkerIds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclusterGraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclusterIds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Assigned 0 workers instead of 31"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'workerIds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-dbbfeb45e7dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'workerIds,partition,clusterGraph,clusterIds=assignWorkers(F,nbWorkers)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkerIds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'workerIds' is not defined"
     ]
    }
   ],
   "source": [
    "%time workerIds,partition,clusterGraph,clusterIds=assignWorkers(F,nbWorkers)\n",
    "print(workerIds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we distantiated workers based on the whole graph (as if one unique community)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%time workerIds=F.vs[maxShortestPathNodesSelection(F,nbWorkers)][\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, cluster in enumerate(clusterGraph.vs):\n",
    "    if cluster.index in clusterIds:\n",
    "        cluster[\"size\"]=50\n",
    "    cluster[\"color\"]=partition.subgraph(idx).vs[0][\"color\"]\n",
    "    cluster[\"label\"]=\"{}({})\".format(idx,cluster[\"nb_workers\"])\n",
    "ig.plot(clusterGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in F.vs:\n",
    "    if v[\"name\"] in workerIds:\n",
    "        v[\"size\"]=25\n",
    "        v[\"shape\"]=\"triangle\"\n",
    "    else:\n",
    "        v[\"size\"]=1\n",
    "        v[\"shape\"]=\"circle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "G=F.to_graph_tool(vertex_attributes={\"color\":\"vector<float>\",\"size\":\"int\",\"shape\":\"string\"},edge_attributes={\"color\":\"vector<float>\"})\n",
    "gt.graph_draw(G, vertex_fill_color=G.vertex_properties[\"color\"],vertex_shape=G.vertex_properties[\"shape\"],vertex_size=G.vertex_properties[\"size\"],edge_color=G.edge_properties[\"color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a list of nodes, give distances between nodes\n",
    "def calcDistBtwnNodes(graph,chosenNodeNames):\n",
    "    return graph.shortest_paths_dijkstra(source=chosenNodeNames, target=chosenNodeNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matPCC=calcDistBtwnNodes(F,workerIds)\n",
    "PCCList=[]\n",
    "for sublist in matPCC:\n",
    "    PCCList.extend(sublist)\n",
    "maxDist=max(PCCList)\n",
    "PCCSelf=[]\n",
    "PCCSameCluster=[]\n",
    "PCCOtherCluster=[]\n",
    "\n",
    "for i, dists in enumerate(matPCC):\n",
    "    source=F.vs.find(workerIds[i])\n",
    "    for j in range(i+1):\n",
    "        target=F.vs.find(workerIds[j])\n",
    "        #print(source,target)\n",
    "        if source[\"name\"]==target[\"name\"]:\n",
    "            PCCSelf.append(matPCC[i][j])\n",
    "        elif source[\"cluster\"]==target[\"cluster\"]:\n",
    "            PCCSameCluster.append(matPCC[i][j])\n",
    "        else:\n",
    "            PCCOtherCluster.append(matPCC[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data=[PCCSelf,PCCSameCluster,PCCOtherCluster]\n",
    "colors=[\"grey\",\"red\",\"blue\"]\n",
    "labels=[\"self\",\"same community\",\"other community\"]\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 100, 1) # fixed bin size\n",
    "\n",
    "plt.xlim([0, maxDist+1])\n",
    "plt.yscale(\"log\")\n",
    "plt.hist(data, bins=bins, color=colors, label=labels, stacked=True)\n",
    "plt.title('Shortest path lengths between workers')\n",
    "plt.xlabel('Shortest path length')\n",
    "plt.ylabel('Count of workers')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(\"Same\",Counter(PCCSameCluster))\n",
    "print(\"Other\",Counter(PCCOtherCluster))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/histograms-and-density-plots-in-python-f6bda88f5ac0\n",
    "Stacked bars to see same and different community node distances\n",
    "\n",
    "https://www.w3resource.com/graphics/matplotlib/barchart/matplotlib-barchart-exercise-16.php\n",
    "to annotate values on stacked bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the greater the value, the better\n",
    "print(sum(PCCList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max distance between nodes (graph diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F.diameter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distances inter-nodes intra-clusters (cluster diameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs=partition.subgraphs()\n",
    "diameters=list([subgraph.diameter() for subgraph in subgraphs])\n",
    "plt.plot(diameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radii=list([subgraph.radius() for subgraph in subgraphs])\n",
    "plt.plot(radii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricities=list([subgraph.eccentricity() for subgraph in subgraphs])\n",
    "print(eccentricities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes per community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "nbClusters=len(Counter(F.vs[\"cluster\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, nbClusters+1, 1)\n",
    "plt.hist(F.vs[\"cluster\"], bins=bins)\n",
    "plt.title('Number of nodes in communities')\n",
    "plt.xlabel('Community')\n",
    "plt.ylabel('Count of nodes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workers per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data=[F.vs.find(worker)[\"cluster\"] for worker in workerIds]\n",
    "bins = np.arange(0, nbClusters+1, 1)\n",
    "plt.hist(data, bins=bins)\n",
    "plt.title('Number of workers in communities')\n",
    "plt.xlabel('Community')\n",
    "plt.ylabel('Count of workers')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster diameter based worker count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameters=[subgraph.diameter() for subgraph in partition.subgraphs()]\n",
    "\n",
    "workers=[diameter//2+diameter%2 for diameter in diameters]\n",
    "assignedWorkers=sum(workers)\n",
    "print(assignedWorkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import pylab\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "# Generate features and distance matrix.\n",
    "D = scipy.zeros([len(matPCC),len(matPCC)])\n",
    "for i in range(40):\n",
    "    for j in range(40):\n",
    "        D[i,j] = matPCC[i][j]\n",
    "\n",
    "# Compute and plot dendrogram.\n",
    "fig = pylab.figure()\n",
    "axdendro = fig.add_axes([0.09,0.1,0.2,0.8])\n",
    "Y = sch.linkage(D, method='centroid')\n",
    "Z = sch.dendrogram(Y, orientation='right')\n",
    "axdendro.set_xticks([])\n",
    "axdendro.set_yticks([])\n",
    "\n",
    "# Plot distance matrix.\n",
    "axmatrix = fig.add_axes([0.3,0.1,0.6,0.8])\n",
    "index = Z['leaves']\n",
    "D = D[index,:]\n",
    "D = D[:,index]\n",
    "im = axmatrix.matshow(D, aspect='auto', origin='lower')\n",
    "axmatrix.set_xticks([])\n",
    "axmatrix.set_yticks([])\n",
    "\n",
    "# Plot colorbar.\n",
    "axcolor = fig.add_axes([0.91,0.1,0.02,0.8])\n",
    "pylab.colorbar(im, cax=axcolor)\n",
    "\n",
    "# Display and save figure.\n",
    "fig.show()\n",
    "fig.savefig('dendrogram.png')\n",
    "\n",
    "#Dendrogram and distance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import itertools\n",
    "def capacityBasedWorkerAssignment(graph,partition,clusterGraph,nWorkers):\n",
    "    assignedWorkers=0\n",
    "    nbClusters=len(partition)\n",
    "    candidatesDict={clusterId:{} for clusterId in range(nbClusters)}\n",
    "    diameters=[subgraph.diameter() for subgraph in partition.subgraphs()]\n",
    "    \n",
    "    cliques=[idx for idx in range(nbClusters) if diameters[idx]==1]\n",
    "    \n",
    "    for clusterId, subgraph in enumerate(partition.subgraphs()):\n",
    "        diameter=diameters[clusterId]\n",
    "        radius=int(subgraph.radius())\n",
    "        \n",
    "        print(\"d\",diameter,\"r\", radius)\n",
    "        if clusterId not in cliques:\n",
    "            for eccentricity in reversed(list(range(2,diameter+1))):#if diameter is 1 => clique => only one worker should be placed\n",
    "                print(\"e\",eccentricity)\n",
    "                candidatesDict[clusterId][eccentricity]=subgraphCapacity(subgraph,eccentricity)\n",
    "        else:\n",
    "            candidatesDict[clusterId][1]=None\n",
    "            clusterGraph[clusterId][\"nb_workers\"]=1 #because all nodes know each other\n",
    "    print(candidatesDict)\n",
    "    \n",
    "    betweenness=clusterGraph.betweenness()\n",
    "    \n",
    "    sortedBtwnsIdx=sorted(range(len(clusterGraph.vs)), key=lambda k: (diameters[k],betweenness[k]), reverse=True)\n",
    "    print(sortedBtwnsIdx)\n",
    "    \n",
    "    eccIdx=diameters.copy()\n",
    "    unsolvedClusters={}\n",
    "    for idx in range(nbClusters):\n",
    "        if idx not in cliques:\n",
    "            #candidatesDict[idx][eccIdx[idx]]=next(candidatesDict[idx][eccIdx[idx]],None)\n",
    "            for minDist in candidatesDict[idx].keys():\n",
    "                candidatesDict[idx][minDist]=next(candidatesDict[idx][minDist],None)\n",
    "                #None values happen when the search space is vast, i.e close to the initial graph, when minDist is low (2 or 3)\n",
    "                #This means there isn't a particular need to find optimal values if nodes are that close, but if we find a solution anyway, good for us.\n",
    "                #If we didn't find a solution, we'll use approximation functions later\n",
    "                if candidatesDict[idx][minDist] is None and unsolvedClusters.get(idx) is None:#Check unsolvedC[idx] is None because we search from the biggest distantiation to the lowest => no overwriting\n",
    "                    unsolvedClusters[idx]=minDist\n",
    "    print(candidatesDict)\n",
    "    #Now we have a certain amount of clusters with distantiated nodes and may have clusters which timed out on the search\n",
    "    #Those timed out clusters will receive workers through other methods\n",
    "    \n",
    "    nbCurrentWorkers={(minDist,maxDist):sum([len(candidatesDict[idx][min(eccIdx[idx],maxDist)]) \n",
    "                                   for idx in range(nbClusters) \n",
    "                                   if candidatesDict[idx][min(eccIdx[idx],maxDist)] is not None and eccIdx[idx]>=minDist]) \n",
    "                      for (minDist,maxDist) in itertools.product(range(2, max(diameters)+1),range(2, max(diameters)+1))\n",
    "                         if minDist<=maxDist}\n",
    "    print(\"nbCurWrks\",nbCurrentWorkers)\n",
    "    \n",
    "    workersPerUnsolvedClusters={idx:1+diameters[idx]//2 for idx in unsolvedClusters.keys()}\n",
    "    workersInUnsolvedClustersInfDist={minDistLimit:sum([workersPerUnsolvedClusters[clusterId] \n",
    "                                            for clusterId,minDist \n",
    "                                            in unsolvedClusters.items() if minDist<=minDistLimit]) \n",
    "                                       for minDistLimit in range(max(diameters))}\n",
    "    totalWorkersInCliques=len(cliques)\n",
    "    \n",
    "    maxMinDistEnoughWorkers=max([minMax[0] for minMax,nbPlacedWorkers in nbCurrentWorkers.items() \n",
    "                                     if nbPlacedWorkers + workersPerUnsolvedClustersInfDist[minMax[0]] + totalWorkersInCliques\n",
    "                                         >=nWorkers],\n",
    "                                default=1)\n",
    "    \n",
    "    if maxMinDistEnoughWorkers==1:\n",
    "        print(\"We haven't found a solution *yet*\")\n",
    "    else:\n",
    "        print(\"Best minDist: \",maxMinDistEnoughWorkers)\n",
    "        maxMaxDistEnoughWorkers=max([minMax[1] for minMax,nbPlacedWorkers in nbCurrentWorkers.items() \n",
    "                                     if minMax[0]==maxMinDistEnoughWorkers and \n",
    "                                         nbPlacedWorkers + workersPerUnsolvedClustersInfDist[minMax[0]] + totalWorkersInCliques\n",
    "                                         >=nWorkers ])\n",
    "        print(\"Best maxDist: \",maxMaxDistEnoughWorkers)\n",
    "        print(\"Workers to be assigned: \",nWorkers)\n",
    "        print(\"Workers in clique communities: \",totalWorkersInCliques)\n",
    "        print(\"Workers in unsolved communities: \",workersPerUnsolvedClustersInfDist[maxMinDistEnoughWorkers])\n",
    "        newEccIdx=[min(idx,maxMaxDistEnoughWorkers) for idx in eccIdx]\n",
    "        assignedSolvedWorkers={cIdx:{\"minDist\":newEccIdx[cIdx],\"workers\":candidatesDict[cIdx][newEccIdx[cIdx]]} for cIdx in range(nbClusters) if newEccIdx[cIdx]>= maxMinDistEnoughWorkers and candidatesDict[cIdx][newEccIdx[cIdx]] is not None}\n",
    "        print(\"Number of workers in solved communities: \",sum([len(value) for value in assignedSolvedWorkers.values()]))\n",
    "        print(\"Workers in solved communities: \",assignedSolvedWorkers)\n",
    "        clusterIdsByMinDist=sorted(assignedSolvedWorkers.keys(), key=lambda k: assignedSolvedWorkers[k][\"minDist\"], reverse=False)\n",
    "        workersToAssignInSolvedClusters=nWorkers-totalWorkersInCliques-\n",
    "        \n",
    "    assert all([cluster[\"nb_workers\"]>=1 for cluster in clusterGraph.vs]), \"{}\".format(clusterGraph.vs[\"nb_workers\"])\n",
    "    assert assignedWorkers==nWorkers, \"Only {} assigned workers out of {}\".format(assignedWorkers,nWorkers)\n",
    "    return clusterGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(candidatesDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
