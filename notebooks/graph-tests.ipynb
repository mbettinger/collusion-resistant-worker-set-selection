{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool.all as gt\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvGraphsPath=\"../graphs/csv/\"\n",
    "csvGraphFileName=\"facebook_combined.csv\"\n",
    "csvGraphFilePath=csvGraphsPath+csvGraphFileName\n",
    "fbGraph=gt.load_graph_from_csv(csvGraphFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F=ig.Graph.Read(\"../graphs/ncol/facebook_combined.txt\",format=\"ncol\").as_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbWorkers=31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "class TimeoutException(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deadline(timeout, *args):\n",
    "    \"\"\"is a the decotator name with the timeout parameter in second\"\"\"\n",
    "    def decorate(f):\n",
    "        \"\"\" the decorator creation \"\"\"\n",
    "        def handler(signum, frame):\n",
    "            \"\"\" the handler for the timeout \"\"\"\n",
    "            raise TimeoutException() #when the signal have been handle raise the exception\n",
    "\n",
    "        def new_f(*args):\n",
    "            \"\"\" the initiation of the handler, \n",
    "            the lauch of the function and the end of it\"\"\"\n",
    "            signal.signal(signal.SIGALRM, handler) #link the SIGALRM signal to the handler\n",
    "            signal.alarm(timeout) #create an alarm of timeout second\n",
    "            res = f(*args) #lauch the decorate function with this parameter\n",
    "            signal.alarm(0) #reinitiate the alarm\n",
    "            return res #return the return value of the fonction\n",
    "    \n",
    "        new_f.__name__ = f.__name__\n",
    "        return new_f\n",
    "    return decorate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import math\n",
    "def colorDistribution(nbColors):\n",
    "    assert nbColors>=1\n",
    "    base=13\n",
    "    maxValues=4\n",
    "    nbValues=math.ceil(nbColors/base)\n",
    "    if nbValues==1:\n",
    "        values=[1]\n",
    "    else:\n",
    "        denominatorV=min(maxValues,nbValues)\n",
    "        values=[min(1,0.5+0.5*v/(denominatorV-1)) for v in range(denominatorV)]\n",
    "\n",
    "    if nbColors==1:\n",
    "        hues=[0]\n",
    "    else:\n",
    "        denominatorH=min(base,nbColors)\n",
    "        hues=[h/(denominatorH) for h in range(denominatorH)]\n",
    "    sats=[1]\n",
    "    nbSat=1\n",
    "    if nbValues>maxValues:\n",
    "        nbSat=math.ceil(nbColors/(denominatorH*denominatorV))\n",
    "        sats=[min(1,0.4+0.5*s/(nbSat-1)) for s in range(nbSat)]\n",
    "    HSVs=[]\n",
    "    \n",
    "    for value in values[::-1]:\n",
    "        for i in range(len(hues)):\n",
    "            for sat in sats[::-1]:\n",
    "                if i%2==0:\n",
    "                    HSVs.append((hues[i//2],sat,value))\n",
    "                else:\n",
    "                    HSVs.append((hues[-i//2],sat,value))\n",
    "\n",
    "    colours = [colorsys.hsv_to_rgb(hue, sat, value) for hue,sat,value in HSVs]\n",
    "    return colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCommunities(graph):\n",
    "    detect_communities=[graph.community_multilevel,\n",
    "                        graph.community_label_propagation,\n",
    "                        graph.community_leading_eigenvector]\n",
    "    \n",
    "    partition=detect_communities[0]()\n",
    "    \n",
    "    colours=colorDistribution(len(partition))\n",
    "\n",
    "    for idx, c in enumerate(partition):\n",
    "        color=colours[idx]\n",
    "        for v in c:\n",
    "            partition.graph.vs[v][\"color\"]=color\n",
    "            partition.graph.vs[v][\"cluster\"]=idx\n",
    "            for e in partition.graph.incident(v):\n",
    "                ed=partition.graph.es[e]\n",
    "                if ed.source in c and ed.target in c:\n",
    "                    ed[\"color\"]=[0.,0.,0.,1.]\n",
    "                else:\n",
    "                    ed[\"color\"]=[0.5,0.5,0.5,1.]\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseVertexByMinBetweenness(graph):\n",
    "    node=None\n",
    "    minBetweenness = -1\n",
    "    for idx, betweenness in enumerate(graph.betweenness()):\n",
    "        if betweenness < minBetweenness or minBetweenness == -1 :\n",
    "            node= idx\n",
    "        if betweenness==0:\n",
    "            break\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseVertexByMaxEccentricity(graph):\n",
    "    node=None\n",
    "    maxEccentricity = 0\n",
    "    diameter=graph.diameter()\n",
    "    for idx, ecc in enumerate(graph.eccentricities()):\n",
    "        if ecc > maxEccentricity:\n",
    "            node= idx\n",
    "        if maxEccentricity==diameter:\n",
    "            break\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseVertexMaxShortestPathsSum(graph):\n",
    "    node=None\n",
    "    maxPCCSum = 0\n",
    "    for idx, pccs in enumerate(graph.shortest_paths_dijkstra()):\n",
    "        sumPCCs=sum(pccs)\n",
    "        if sumPCCs > maxPCCSum:\n",
    "            node= idx\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choiceFunctions=[chooseVertexByMinBetweenness,chooseVertexByMaxEccentricity,chooseVertexMaxShortestPathsSum]\n",
    "chosenFunction=choiceFunctions[2]\n",
    "def chooseVertex(graph,choiceFunction=chosenFunction):\n",
    "    assert len(graph.vs)>0, \"Can't choose a vertex in an empty graph.\" \n",
    "    node=None\n",
    "    node=choiceFunction(graph)\n",
    "    print(graph.vs[node])\n",
    "    assert node is not None\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanceCrit(value):\n",
    "    outputs=[0,0,5,10]\n",
    "    if value>=len(outputs):\n",
    "        return outputs[-1]\n",
    "    return outputs[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxMinPCCNodeSelection(dictPCC):\n",
    "    assert dictPCC!={}\n",
    "    chosenId=None\n",
    "    nbNodes=len(list(dictPCC.values())[0])\n",
    "    maxDist=-1\n",
    "    maxSumDist=-1\n",
    "    maxDistNode=None\n",
    "    for nodeId in range(nbNodes):\n",
    "        if nodeId not in dictPCC.keys():\n",
    "            minDist=-1\n",
    "            minDistNode=nodeId\n",
    "            for chosenNode in dictPCC.keys():\n",
    "                if minDist==-1 or dictPCC[chosenNode][nodeId]<minDist:\n",
    "                    minDist=dictPCC[chosenNode][nodeId]\n",
    "            #if equivalent on criterion 1, calculate criterion 2\n",
    "            sumDist=-1\n",
    "            if maxSumDist==-1 or minDist==maxDist:\n",
    "                #sumDist=sum([dictPCC[chosenNode][nodeId] for chosenNode in dictPCC.keys()])\n",
    "                #sumDist=random()\n",
    "                sumDist=sum([distanceCrit(dictPCC[chosenNode][nodeId]) for chosenNode in dictPCC.keys()])\n",
    "            #if better crit1 or equal crit1 but better crit2\n",
    "            if minDist>maxDist or (minDist==maxDist and sumDist>maxSumDist):\n",
    "                maxDist=minDist\n",
    "                maxDistNode=minDistNode\n",
    "                maxSumDist=sumDist\n",
    "    chosenId=maxDistNode\n",
    "    return chosenId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxShortestPathNodesSelection(graph,nbNodes,boundaryNodes=[]):\n",
    "    assert len(graph.vs)-len(boundaryNodes)>= nbNodes, \"{} {} {}\".format(len(graph.vs),nbNodes,len(boundaryNodes))\n",
    "    if boundaryNodes==[]:\n",
    "        chosenIds=[chooseVertex(graph)]\n",
    "    else:\n",
    "        chosenIds=boundaryNodes.copy()\n",
    "    #BFS initial des noeuds dans chosenIds\n",
    "    matPCC=graph.shortest_paths_dijkstra(chosenIds)\n",
    "    dictPCC={chosenId:matPCC[idxPCC] for idxPCC,chosenId in enumerate(chosenIds)}\n",
    "    \n",
    "    #nbNodes fois\n",
    "    while len(chosenIds)-len(boundaryNodes)<nbNodes:\n",
    "        chosenNodeId=maxMinPCCNodeSelection(dictPCC)\n",
    "\n",
    "        #BFS du nouveau noeud\n",
    "        dictPCC[chosenNodeId]=graph.shortest_paths_dijkstra(chosenNodeId)[0] #On prend la ligne de la matrice qui correspond au noeud\n",
    "        chosenIds.append(chosenNodeId)\n",
    "    assert len(chosenIds)==len(boundaryNodes)+nbNodes\n",
    "    return chosenIds[len(boundaryNodes):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineBoundary(graph, clusterVertices, clusterId):\n",
    "    boundaryVertices=set()\n",
    "    for v in clusterVertices: #Trouver les successeurs hors cluster aka les noeuds frontaliers au cluster\n",
    "        boundaryVertices.update([bv for bv in v.successors() if bv[\"cluster\"]!=clusterId])\n",
    "    boundaryVertices=list(boundaryVertices)\n",
    "    \n",
    "    return boundaryVertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBoundedCluster(boundedCluster,workerIds,clusterId):\n",
    "    for node in boundedCluster.vs:\n",
    "        if node[\"name\"]in boundedCluster.vs[workerIds][\"name\"]:\n",
    "            node[\"shape\"]=\"triangle\"\n",
    "\n",
    "    ig.plot(boundedCluster,\"../graphs/img/cluster{}.png\".format(clusterId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withBoundary=False\n",
    "def assignWorkersInCommunity(graph,clusterGraph,clusterId,withBoundary=withBoundary):\n",
    "    clusterVertices=[v for v in graph.vs if v[\"cluster\"]==clusterId]\n",
    "    \n",
    "    boundaryVertices=[]\n",
    "    if withBoundary:\n",
    "        boundaryVertices=defineBoundary(graph,clusterVertices,clusterId)\n",
    "    \n",
    "    boundedCluster=graph.induced_subgraph(boundaryVertices+clusterVertices)\n",
    "    \n",
    "    #Réidentification des noeuds du graphe global vers le sous-graphe\n",
    "    #clusterVertices=[boundedCluster.vs.find(v[\"name\"]) for v in clusterVertices]\n",
    "    boundaryVertices=[boundedCluster.vs.find(v[\"name\"]) for v in boundaryVertices]\n",
    "    boundaryVerticesIds=[bv.index for bv in boundaryVertices]\n",
    "    \n",
    "    workerIds=maxShortestPathNodesSelection(boundedCluster,clusterGraph.vs[clusterId][\"nb_workers\"],boundaryVerticesIds)\n",
    "    \n",
    "    #drawBoundedCluster(boundedCluster,workerIds,clusterId)\n",
    "    \n",
    "    return boundedCluster.vs[workerIds][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atLeastNWorkers(minWorkers):\n",
    "    def wrap(f):\n",
    "        def wrapped_f(graph,partition,clusterGraph,nWorkers):\n",
    "            #Chaque cluster aura au moins un worker en lui\n",
    "            for cluster in clusterGraph.vs:\n",
    "                cluster[\"nb_workers\"]=minWorkers\n",
    "\n",
    "            #Attribuer le nombre de workers réel\n",
    "            remainingWorkers=nWorkers-minWorkers*len(clusterGraph.vs)\n",
    "            res=f(graph,partition,clusterGraph,remainingWorkers)\n",
    "            return res\n",
    "        return wrapped_f\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def subgraphCapacity(graph, minDist):\n",
    "    nodes=graph.vs\n",
    "    candidates=set()\n",
    "    matPCC=graph.shortest_paths_dijkstra()\n",
    "\n",
    "    dfPCC=pd.DataFrame(matPCC,nodes[\"name\"],nodes[\"name\"])\n",
    "    #print((dfPCC > minDist).values)\n",
    "    g = ig.Graph.Adjacency((dfPCC >= minDist).values.tolist()).as_undirected()\n",
    "    g.vs[\"name\"]=nodes[\"name\"]\n",
    "    #ig.plot(g,\"../graphs/img/graph.png\")\n",
    "    #print(g)\n",
    "    try:\n",
    "        cliques=deadline(10)(g.largest_cliques)()\n",
    "        candidates=[nodes[idx][\"name\"] for idx in cliques[0]]\n",
    "        \n",
    "        print(\"n_clq\",len(cliques),\"l_clq\", len(cliques[0]),\"a clq\", cliques[0])\n",
    "        print(\"len(c)\",len(candidates),\"len(n)\",len(nodes))\n",
    "        yield candidates\n",
    "    except TimeoutException:\n",
    "        print(\"Timeout\")\n",
    "        candidates=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "@atLeastNWorkers(0)\n",
    "def capacityBasedWorkerAssignment(graph,partition,clusterGraph,nWorkers):\n",
    "    assignedWorkers=0\n",
    "    nbClusters=len(partition)\n",
    "    candidatesDict={clusterId:{} for clusterId in range(nbClusters)}\n",
    "    diameters=[subgraph.diameter() for subgraph in partition.subgraphs()]\n",
    "    \n",
    "    cliques=[idx for idx in range(nbClusters) if diameters[idx]==1]\n",
    "    \n",
    "    for clusterId, subgraph in enumerate(partition.subgraphs()):\n",
    "        diameter=diameters[clusterId]\n",
    "        radius=int(subgraph.radius())\n",
    "        \n",
    "        print(\"d\",diameter,\"r\", radius)\n",
    "        if clusterId not in cliques:\n",
    "            for eccentricity in reversed(list(range(2,diameter+1))):#if diameter is 1 => clique => only one worker should be placed\n",
    "                print(\"e\",eccentricity)\n",
    "                candidatesDict[clusterId][eccentricity]=subgraphCapacity(subgraph,eccentricity)\n",
    "        else:\n",
    "            candidatesDict[clusterId][1]=None\n",
    "            clusterGraph[clusterId][\"nb_workers\"]=1 #because all nodes know each other\n",
    "    print(candidatesDict)\n",
    "    \n",
    "    betweenness=clusterGraph.betweenness()\n",
    "    \n",
    "    sortedBtwnsIdx=sorted(range(len(clusterGraph.vs)), key=lambda k: (diameters[k],betweenness[k]), reverse=True)\n",
    "    print(sortedBtwnsIdx)\n",
    "    \n",
    "    eccIdx=diameters.copy()\n",
    "    for idx in range(nbClusters):\n",
    "        #candidatesDict[idx][eccIdx[idx]]=next(candidatesDict[idx][eccIdx[idx]],None)\n",
    "        for key in candidatesDict[idx].keys():\n",
    "            candidatesDict[idx][key]=next(candidatesDict[idx][key],None)\n",
    "            #None values happen when the search space is vast, i.e close to the initial graph, when minDist is low (2 or 3)\n",
    "            #This means there isn't a particular need to find optimal values if nodes are that close, but if we find a solution anyway, good for us.\n",
    "            #If we didn't find a solution, we'll use approximation functions later\n",
    "\n",
    "    print(candidatesDict)\n",
    "    #Now we have a certain amount of clusters with distantiated nodes and may have clusters which timed out on the search\n",
    "    #Those timed out clusters will receive workers through other methods\n",
    "    \n",
    "    nbCurrentWorkers={(minDist,maxDist):sum([len(candidatesDict[idx][min(eccIdx[idx],maxDist)]) \n",
    "                                   for idx in range(nbClusters) \n",
    "                                   if candidatesDict[idx][min(eccIdx[idx],maxDist)] is not None and eccIdx[idx]>=minDist]) \n",
    "                      for (minDist,maxDist) in itertools.product(range(2, max(diameters)+1),range(2, max(diameters)+1))\n",
    "                         if minDist<=maxDist}\n",
    "    print(\"nbCurWrks\",nbCurrentWorkers)\n",
    "    \n",
    "    unsolvedClusters={(minDist,maxDist):[cluster for cluster in range(nbClusters)\n",
    "                                            if eccIdx[cluster]<minDist \n",
    "                                            or all([candidatesDict[cluster][ecc] is None \n",
    "                                                    for ecc in range(minDist,min(eccIdx[cluster],maxDist)+1)])\n",
    "                                        ] for (minDist,maxDist) in nbCurrentWorkers.keys()}\n",
    "    print(\"unsolved\",unsolvedClusters)\n",
    "    \n",
    "    unsolvedClustersWorkers={(minDist,maxDist):sum([1+diameters[cluster]//2\n",
    "                                                 for cluster in unsolvedClusters[(minDist,maxDist)]])\n",
    "                                 for (minDist,maxDist) in nbCurrentWorkers.keys()}\n",
    "    print(\"unsolvedNbWorkers\",unsolvedClustersWorkers)\n",
    "    \n",
    "    totalWorkersInCliques=len(cliques)\n",
    "    \n",
    "    maxMinDistEnoughWorkers=1\n",
    "    counter=0\n",
    "    while maxMinDistEnoughWorkers==1:\n",
    "        counter+=1\n",
    "        maxMinDistEnoughWorkers=max([minDist for (minDist,maxDist),nbPlacedWorkers in nbCurrentWorkers.items() \n",
    "                                         if nbPlacedWorkers \n",
    "                                             + min(counter*len(unsolvedClusters[(minDist,maxDist)]),\n",
    "                                                   unsolvedClustersWorkers[(minDist,maxDist)]) \n",
    "                                             + totalWorkersInCliques\n",
    "                                             >=nWorkers],\n",
    "                                    default=1)\n",
    "    print(\"nbFoisLen\",counter)\n",
    "    \n",
    "    if maxMinDistEnoughWorkers==1:\n",
    "        print(\"We haven't found a solution *yet*, might as well abort...\")\n",
    "    else:\n",
    "        print(\"Best minDist: \",maxMinDistEnoughWorkers)\n",
    "        maxMaxDistEnoughWorkers=max([maxDist for (minDist,maxDist),nbPlacedWorkers in nbCurrentWorkers.items() \n",
    "                                     if minDist==maxMinDistEnoughWorkers and \n",
    "                                         nbPlacedWorkers + unsolvedClustersWorkers[(minDist,maxDist)] + totalWorkersInCliques\n",
    "                                         >=nWorkers ])\n",
    "        minMax=(maxMinDistEnoughWorkers,maxMaxDistEnoughWorkers)\n",
    "        print(\"Best maxDist: \",maxMaxDistEnoughWorkers)\n",
    "        print(\"Workers to be assigned: \",nWorkers)\n",
    "        print(\"Workers in clique communities: \",totalWorkersInCliques)\n",
    "        print(\"Workers in unsolved communities: \",unsolvedClustersWorkers[minMax])\n",
    "        newEccIdx=[min(idx,maxMaxDistEnoughWorkers) for idx in eccIdx]\n",
    "        assignedSolvedWorkers={cIdx:{\"minDist\":newEccIdx[cIdx],\n",
    "                                     \"workers\":candidatesDict[cIdx][newEccIdx[cIdx]]} \n",
    "                                for cIdx in range(nbClusters) \n",
    "                                if newEccIdx[cIdx]>= maxMinDistEnoughWorkers \n",
    "                                       and candidatesDict[cIdx][newEccIdx[cIdx]] is not None}\n",
    "        print(\"Number of workers in solved communities: \",sum([len(value) for value in assignedSolvedWorkers.values()]))\n",
    "        print(\"Workers in solved communities: \",assignedSolvedWorkers)\n",
    "        clusterIdsByMinDist=sorted(assignedSolvedWorkers.keys(), key=lambda k: assignedSolvedWorkers[k][\"minDist\"], reverse=False)\n",
    "        #Check if you can assign 1 worker to clique (1 per clq) and unsolved clusters and complete with solved cluster workers\n",
    "        workersToAssignInSolvedClusters=nWorkers-totalWorkersInCliques-unsolvedClustersWorkers[minMax]\n",
    "        \n",
    "        for cluster in cliques:\n",
    "            clusterGraph.vs[cluster][\"nb_workers\"]=1\n",
    "        assignedWorkers+=len(cliques)\n",
    "            \n",
    "        print(\"w\",workersToAssignInSolvedClusters,nbCurrentWorkers[minMax])\n",
    "        if workersToAssignInSolvedClusters<nbCurrentWorkers[minMax]:\n",
    "            #Unsolved clusters get 1 worker\n",
    "            for cluster in unsolvedClusters[minMax]:\n",
    "                clusterGraph.vs[cluster][\"nb_workers\"]=1\n",
    "            assignedWorkers+=len(unsolvedClusters[minMax])\n",
    "            \n",
    "            #We need to remove some workers in the solved clusters\n",
    "            #We first do as if we put all of them in\n",
    "            assignedWorkers+=nbCurrentWorkers[minMax]\n",
    "            for cluster in assignedSolvedWorkers.keys():\n",
    "                #We keep the exact workers lists in solved clusters\n",
    "                clusterGraph.vs[cluster][\"nb_workers\"]=len(assignedSolvedWorkers[cluster][\"workers\"])\n",
    "            #Then we remove excess workers\n",
    "            clustersPerDist={currentDist:[cluster for cluster,infos in assignedSolvedWorkers.items() \n",
    "                                          if infos[\"minDist\"]==currentDist]\n",
    "                                for currentDist in reversed(list(range(minMax[0],minMax[1]+1)))\n",
    "                            }\n",
    "            print(\"-1\",assignedWorkers)\n",
    "            while assignedWorkers>nbWorkers:\n",
    "                for clusters in clustersPerDist.values():\n",
    "                    succeeded=True\n",
    "                    while(succeeded):\n",
    "                        succeeded=False\n",
    "                        for cluster in clusters:\n",
    "                            if clusterGraph.vs[cluster][\"nb_workers\"]>2:\n",
    "                                assignedSolvedWorkers[cluster][\"workers\"].pop()\n",
    "                                assignedWorkers-=1\n",
    "                                succeeded=True\n",
    "                                print(\"0\",assignedWorkers)\n",
    "                            print(\"1\",assignedWorkers)\n",
    "                            if assignedWorkers==nbWorkers:\n",
    "                                succeeded=True\n",
    "                                break\n",
    "                            print(\"1a\",assignedWorkers)\n",
    "                        print(\"2\",assignedWorkers)\n",
    "                    print(\"3\",assignedWorkers)\n",
    "                    if assignedWorkers==nbWorkers:\n",
    "                        break\n",
    "                print(\"4\",assignedWorkers)\n",
    "            print(\"5\",assignedWorkers)\n",
    "        else:#We know there is enough room in unsolved clusters\n",
    "            for cluster in assignedSolvedWorkers.keys():\n",
    "                #We keep the exact workers lists in solved clusters\n",
    "                clusterGraph.vs[cluster][\"nb_workers\"]=len(assignedSolvedWorkers[cluster][\"workers\"])\n",
    "            assignedWorkers+=nbCurrentWorkers[minMax]\n",
    "            #We assign the unsolved cluster workers with the diameter based method\n",
    "            remainingWorkers=nbWorkers-assignedWorkers\n",
    "            \n",
    "            clusterGraph=diameterWorkerAssignment(graph,partition,clusterGraph,remainingWorkers,unsolvedClusters[minMax])\n",
    "            assignedWorkers+=remainingWorkers\n",
    "            \n",
    "    assert all([cluster[\"nb_workers\"]>=1 for cluster in clusterGraph.vs]), \"{}\".format(clusterGraph.vs[\"nb_workers\"])\n",
    "    assert assignedWorkers==nWorkers, \"Only {} assigned workers out of {}\".format(assignedWorkers,nWorkers)\n",
    "    clustersToFill=[*unsolvedClusters[minMax],*cliques]\n",
    "    return [],clusterGraph,clustersToFill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@atLeastNWorkers(1)\n",
    "def sizeOrderedRoundRobinWorkerAssignement(graph,partition,clusterGraph,remainingWorkers):\n",
    "    graphSize=len(graph.vs)\n",
    "    relativeSizes=[len(partition.subgraph(int(cluster[\"name\"][1:])).vs)/graphSize for cluster in clusterGraph.vs]\n",
    "\n",
    "    sortedIdxPerSize=sorted(range(len(relativeSizes)), key=lambda k: relativeSizes[k], reverse=True)\n",
    "    sortedSizes=sorted(relativeSizes)\n",
    "\n",
    "    #Round Robin par ordre de taille des clusters\n",
    "    currentCluster=0\n",
    "    while remainingWorkers>0:\n",
    "        currentSortedCluster=sortedIdxPerSize[currentCluster]\n",
    "        if clusterGraph.vs[currentSortedCluster][\"nb_workers\"]<len(partition.subgraph(currentSortedCluster).vs):\n",
    "            clusterGraph.vs[currentSortedCluster][\"nb_workers\"]+=1\n",
    "            remainingWorkers-=1\n",
    "        currentCluster+=1\n",
    "        if currentCluster>=len(clusterGraph.vs):\n",
    "            currentCluster=0\n",
    "    return [],clusterGraph, range(len(partition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@atLeastNWorkers(1)\n",
    "def sizeProRataWorkerAssignement(graph,partition,clusterGraph,remainingWorkers):\n",
    "    graphSize=len(graph.vs)\n",
    "    relativeSizes=[len(partition.subgraph(int(cluster[\"name\"][1:])).vs)/graphSize for cluster in clusterGraph.vs]\n",
    "\n",
    "    proRataWorkers=[remainingWorkers*size for size in relativeSizes]\n",
    "    intProRataWorkers=[int(prw) for prw in proRataWorkers]\n",
    "    \n",
    "    assignedWorkers=sum(intProRataWorkers)\n",
    "    if assignedWorkers < remainingWorkers:\n",
    "        remainingProRataWorkers=[prw - prw//1 for prw in proRataWorkers]\n",
    "        sortedIdx=sorted(range(len(remainingProRataWorkers)), key=lambda k: remainingProRataWorkers[k], reverse=True)\n",
    "\n",
    "        for i in range(remainingWorkers-assignedWorkers):\n",
    "            intProRataWorkers[sortedIdx[i]]+=1\n",
    "            assignedWorkers+=1\n",
    "        \n",
    "    for idx, cluster in enumerate(clusterGraph.vs):\n",
    "        cluster[\"nb_workers\"]+=intProRataWorkers[idx]\n",
    "    \n",
    "    assert assignedWorkers==remainingWorkers, \"Only {} assigned workers out of {}\".format(assignedWorkers,remainingWorkers)\n",
    "    return [],clusterGraph, range(len(partition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@atLeastNWorkers(1)\n",
    "def diameterProRataWorkerAssignement(graph,partition,clusterGraph,remainingWorkers):\n",
    "\n",
    "    diameters=[subgraph.diameter() for subgraph in partition.subgraphs()]\n",
    "    sumDiameters=sum(diameters)\n",
    "    \n",
    "    proRataWorkers=[remainingWorkers*diameter/sumDiameters for diameter in diameters]\n",
    "    intProRataWorkers=[int(prw) for prw in proRataWorkers]\n",
    "    \n",
    "    assignedWorkers=sum(intProRataWorkers)\n",
    "    if assignedWorkers < remainingWorkers:\n",
    "        remainingProRataWorkers=[prw - prw//1 for prw in proRataWorkers]\n",
    "        sortedIdx=sorted(range(len(remainingProRataWorkers)), key=lambda k: remainingProRataWorkers[k], reverse=True)\n",
    "\n",
    "        for i in range(remainingWorkers-assignedWorkers):\n",
    "            intProRataWorkers[sortedIdx[i]]+=1\n",
    "            assignedWorkers+=1\n",
    "        \n",
    "    for idx, cluster in enumerate(clusterGraph.vs):\n",
    "        cluster[\"nb_workers\"]+=intProRataWorkers[idx]\n",
    "    \n",
    "    assert assignedWorkers==remainingWorkers, \"Only {} assigned workers out of {}\".format(assignedWorkers,remainingWorkers)\n",
    "    return [],clusterGraph, range(len(partition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@atLeastNWorkers(0)\n",
    "def diameterWorkerAssignment(graph,partition,clusterGraph,remainingWorkers,clustersToFill=None):\n",
    "    diameters=[subgraph.diameter() for subgraph in partition.subgraphs()]\n",
    "    \n",
    "    if clustersToFill is None:\n",
    "        clustersToFill=range(len(clusterGraph.vs))\n",
    "    \n",
    "    workers=[1+diameter//2 for diameter in diameters]\n",
    "    assignedWorkers=sum([nb for idx,nb in enumerate(workers) if idx in clustersToFill])\n",
    "    for idx in clustersToFill:\n",
    "        clusterGraph.vs[idx][\"nb_workers\"]=workers[idx]\n",
    "\n",
    "    while assignedWorkers>remainingWorkers:\n",
    "        sortedIdx=sorted(clustersToFill, key=lambda k: workers[k], reverse=True)\n",
    "\n",
    "        for i in range(assignedWorkers-remainingWorkers):\n",
    "            if clusterGraph.vs[sortedIdx[i%len(sortedIdx)]][\"nb_workers\"]>1:\n",
    "                clusterGraph.vs[sortedIdx[i%len(sortedIdx)]][\"nb_workers\"]-=1\n",
    "                assignedWorkers-=1\n",
    "    \n",
    "    if assignedWorkers<remainingWorkers:\n",
    "        clusterGraph=sizeOrderedRoundRobinWorkerAssignement(graph,partition,clusterGraph,remainingWorkers-assignedWorkers)\n",
    "        assignedWorkers=remainingWorkers\n",
    "    \n",
    "    assert assignedWorkers==remainingWorkers, \"Only {} assigned workers out of {}\".format(assignedWorkers,remainingWorkers)\n",
    "    return [],clusterGraph,clustersToFill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignWorkers(graph,nWorkers):\n",
    "    assert nWorkers>=0, \"{} workers to assign: Number of workers to assign must be positive or zero\".format(nWorkers)\n",
    "    assert len(graph.vs)>=nWorkers, \"{} workers to assign on {} nodes: Can't assign more workers than there are vertices\".format(nWorkers,len(graph.vs))\n",
    "    partition=findCommunities(graph)\n",
    "    \n",
    "    clusterGraph=partition.cluster_graph(\"first\")\n",
    "\n",
    "    for idx, cluster in enumerate(clusterGraph.vs):\n",
    "        cluster[\"name\"]=\"C{}\".format(idx)\n",
    "\n",
    "    workerIds=[]\n",
    "    clusterIds=[]\n",
    "    if len(partition)<nWorkers:        \n",
    "        workerAssignment=[sizeProRataWorkerAssignement,\n",
    "                          sizeOrderedRoundRobinWorkerAssignement,\n",
    "                          diameterProRataWorkerAssignement,\n",
    "                          diameterWorkerAssignment,\n",
    "                          capacityBasedWorkerAssignment,\n",
    "                          #subpartitioning\n",
    "                         ]\n",
    "\n",
    "        workerIds,clusterGraph,clusterIds=workerAssignment[3](graph, partition,clusterGraph, nWorkers)\n",
    "        \n",
    "    elif len(partition)==nWorkers:\n",
    "        #1cluster/1worker\n",
    "        for cluster in clusterGraph.vs:\n",
    "            cluster[\"nb_workers\"]=1\n",
    "        clusterIds=range(len(partition))\n",
    "    else:\n",
    "        clusterIds=maxShortestPathNodesSelection(clusterGraph,nWorkers)\n",
    "        for cluster in clusterGraph.vs:\n",
    "            if cluster.index in clusterIds:\n",
    "                cluster[\"nb_workers\"]=1\n",
    "            else:\n",
    "                cluster[\"nb_workers\"]=0\n",
    "\n",
    "    #Etape2\n",
    "    #for chaque cluster de workers\n",
    "    #prendre son sous-graphe+ les noeuds frontaliers d'autres clusters, BFS des frontières et Etape1 nb_workers fois\n",
    "    for clusterId in clusterIds:\n",
    "        %time workerIds.extend(assignWorkersInCommunity(graph,clusterGraph,clusterId))\n",
    "    \n",
    "    assert len(workerIds)==nWorkers, \"Assigned {} workers instead of {}\".format(len(workerIds),nWorkers)\n",
    "    return workerIds,partition,clusterGraph,clusterIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time workerIds,partition,clusterGraph,clusterIds=assignWorkers(F,nbWorkers)\n",
    "print(workerIds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we distantiated workers based on the whole graph (as if one unique community)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%time workerIds=F.vs[maxShortestPathNodesSelection(F,nbWorkers)][\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, cluster in enumerate(clusterGraph.vs):\n",
    "    if cluster.index in clusterIds:\n",
    "        cluster[\"size\"]=50\n",
    "    cluster[\"color\"]=partition.subgraph(idx).vs[0][\"color\"]\n",
    "    cluster[\"label\"]=\"{}({})\".format(idx,cluster[\"nb_workers\"])\n",
    "ig.plot(clusterGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in F.vs:\n",
    "    if v[\"name\"] in workerIds:\n",
    "        v[\"size\"]=25\n",
    "        v[\"shape\"]=\"triangle\"\n",
    "    else:\n",
    "        v[\"size\"]=1\n",
    "        v[\"shape\"]=\"circle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "G=F.to_graph_tool(vertex_attributes={\"color\":\"vector<float>\",\"size\":\"int\",\"shape\":\"string\"},edge_attributes={\"color\":\"vector<float>\"})\n",
    "gt.graph_draw(G, vertex_fill_color=G.vertex_properties[\"color\"],vertex_shape=G.vertex_properties[\"shape\"],vertex_size=G.vertex_properties[\"size\"],edge_color=G.edge_properties[\"color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a list of nodes, give distances between nodes\n",
    "def calcDistBtwnNodes(graph,chosenNodeNames):\n",
    "    return graph.shortest_paths_dijkstra(source=chosenNodeNames, target=chosenNodeNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matPCC=calcDistBtwnNodes(F,workerIds)\n",
    "PCCList=[]\n",
    "for sublist in matPCC:\n",
    "    PCCList.extend(sublist)\n",
    "maxDist=max(PCCList)\n",
    "PCCSelf=[]\n",
    "PCCSameCluster=[]\n",
    "PCCOtherCluster=[]\n",
    "\n",
    "for i, dists in enumerate(matPCC):\n",
    "    source=F.vs.find(workerIds[i])\n",
    "    for j in range(i+1):\n",
    "        target=F.vs.find(workerIds[j])\n",
    "        #print(source,target)\n",
    "        if source[\"name\"]==target[\"name\"]:\n",
    "            PCCSelf.append(matPCC[i][j])\n",
    "        elif source[\"cluster\"]==target[\"cluster\"]:\n",
    "            PCCSameCluster.append(matPCC[i][j])\n",
    "        else:\n",
    "            PCCOtherCluster.append(matPCC[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data=[PCCSelf,PCCSameCluster,PCCOtherCluster]\n",
    "colors=[\"grey\",\"red\",\"blue\"]\n",
    "labels=[\"self\",\"same community\",\"other community\"]\n",
    "# fixed bin size\n",
    "bins = np.arange(0, 100, 1) # fixed bin size\n",
    "\n",
    "plt.xlim([0, maxDist+1])\n",
    "plt.yscale(\"log\")\n",
    "plt.hist(data, bins=bins, color=colors, label=labels, stacked=True)\n",
    "plt.title('Shortest path lengths between workers')\n",
    "plt.xlabel('Shortest path length')\n",
    "plt.ylabel('Count of workers')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(\"Same\",Counter(PCCSameCluster))\n",
    "print(\"Other\",Counter(PCCOtherCluster))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/histograms-and-density-plots-in-python-f6bda88f5ac0\n",
    "Stacked bars to see same and different community node distances\n",
    "\n",
    "https://www.w3resource.com/graphics/matplotlib/barchart/matplotlib-barchart-exercise-16.php\n",
    "to annotate values on stacked bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the greater the value, the better\n",
    "print(sum(PCCList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max distance between nodes (graph diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F.diameter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distances inter-nodes intra-clusters (cluster diameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs=partition.subgraphs()\n",
    "diameters=list([subgraph.diameter() for subgraph in subgraphs])\n",
    "plt.plot(diameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radii=list([subgraph.radius() for subgraph in subgraphs])\n",
    "plt.plot(radii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes per community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "nbClusters=len(Counter(F.vs[\"cluster\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, nbClusters+1, 1)\n",
    "plt.hist(F.vs[\"cluster\"], bins=bins)\n",
    "plt.title('Number of nodes in communities')\n",
    "plt.xlabel('Community')\n",
    "plt.ylabel('Count of nodes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workers per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data=[F.vs.find(worker)[\"cluster\"] for worker in workerIds]\n",
    "bins = np.arange(0, nbClusters+1, 1)\n",
    "plt.hist(data, bins=bins)\n",
    "plt.title('Number of workers in communities')\n",
    "plt.xlabel('Community')\n",
    "plt.ylabel('Count of workers')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster diameter based worker count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameters=[subgraph.diameter() for subgraph in partition.subgraphs()]\n",
    "\n",
    "workers=[diameter//2+diameter%2 for diameter in diameters]\n",
    "assignedWorkers=sum(workers)\n",
    "print(assignedWorkers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
